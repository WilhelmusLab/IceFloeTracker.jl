var documenterSearchIndex = {"docs":
[{"location":"tracking/#Tracking","page":"Tracking","title":"Tracking","text":"Floe tracking in Ice Floe Tracker is based on object shapes and locations. Given a series of segmented images, the goal is to identify shapes that persist across images, subject to constraints on object similarity and maximum displacements. The algorithm has three main components: (1) the main floe_tracker algorithm, which keeps track of the most recent floe in each trajectory (trajectory heads) and the set of candidate matches in the next image, (2) a \"floe filter\" function which identifies all the possible pairs between a trajectory head and floes in the candidate set, and (3) a \"floe matching\" algorithm which identifies a set of unique pairs. By designing and customizing the filter functions and matching functions, the floe_tracker function provides a flexible and powerful platform for developing floe tracking workflows.","category":"section"},{"location":"tracking/#Preparing-data-for-tracking","page":"Tracking","title":"Preparing data for tracking","text":"The floe_tracker takes three positional arguments: a list of DataFrames, a filter function, and a matching function, as well as optional keyword arguments to specify the minimum and maximum floe sizes (in pixels) and the maximum time step in between floe pairs. Assuming that a set of images segmented_images has already been produced, the regionprops_table function produces a DataFrame where each row corresponds to a floe, and each column is some measurement or attribute of the floe. DataFrames are highly flexible–entries in the dataframe are not limited to words and numbers, but can include vectors and matrices as well. At the very least, the property tables will need to include the floe ID, floe area and an associated observation time. Other columns and measures depend on what will be used in the filter function. The regionprops_table function defaults to calculating  area, convex area, centroid, perimeter, major and minor axis, and orientation. We can initialize the property tables using dot notation to broadcast to a list:\n\nprops = regionprops_table.(segmented_images)\n\nWe include helper functions to add unique IDs to each row and to add image observation times. Assuming passtimes is a list of DateTimes of the same length as segmented_images, we run\n\nadd_uuids!(props)\nadd_passtimes!(props, passtimes)\n\nThe default filter functions include calculations based on binary floe shapes (floe masks) and associated psi-s curves. We include helper functions for these as well. For the floe masks, we also need a list with binary images associated with each segmented image.\n\nadd_floemasks!.(props, binary_images)\nadd_ψs(props)","category":"section"},{"location":"tracking/#Floe-Filter-Functions","page":"Tracking","title":"Floe Filter Functions","text":"Floe filter functions take two argmuments: a DataFrameRow corresponding to the floe to be matched, and a DataFrame with candidate pairs from the current time step. These functions should operate in-place and result in DataFrame subsetting operation. IceFloeTracker.jl includes four main AbstractFloeFilterFunctions.  These functions all follow the same procedure:\n\nCompute comparisons between the floe and each floe in the candidates DataFrame\nUse an threshold test to evaluate the comparisons\nReduce the candidates dataframe to only those pairs that pass the threshold test\n\nEach of these functions can be called in series, as they only depend on the columns in the input property tables. TheChainedFilterFunctiontakes a list of filter functions and wraps them into a single function call. Using the struct/functor approach, we can initialize each function with parameters, then pass the function and settings into the floe_tracker function. As an example, let's define a filter function which compares the relative error in area against a step function. We initialize the step function first:\n\nsw = StepwiseLinearThresholdFunction(changepoint_area=500, low_value=0.25, high_value=0.125)\n\nThe function sw will return true if the relative error is less than 0.25 and the area is smaller than 500 pixels. If the area is larger, then a stricter threshold of 0.125 is applied. Next, we make a filter function\n\nrel_err_ff = RelativeErrorThresholdFilter(variable=:area, threshold_function=sw)\n\nThis function will add a column :relative_error_area to the filter function, which can be used in the Matching Function.","category":"section"},{"location":"tracking/#Matching-Function","page":"Tracking","title":"Matching Function","text":"","category":"section"},{"location":"segmentation/#Segmentation","page":"Segmentation","title":"Segmentation","text":"The segmentation functions are intended for use on the preprocessed imagery.","category":"section"},{"location":"segmentation/#Ice/Water-Discrimination","page":"Segmentation","title":"Ice/Water Discrimination","text":"","category":"section"},{"location":"segmentation/#Feature-Identification","page":"Segmentation","title":"Feature Identification","text":"","category":"section"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"(Image: Open this notebook in Colab)","category":"section"},{"location":"tutorials/lopez-acosta-2019-workflow/#Segmentation-Algorithm-Workflows","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"This notebook demonstrates IceFloeTracker.jl's segmentation algorithms  with very basic examples of their use.\n\n\n# Setup environment\nusing Pkg\nPkg.add(;name=\"IceFloeTracker\", rev=\"826/merge\")\nPkg.add(\"Images\")\n\n\n\n# Load packages\nusing IceFloeTracker: LopezAcosta2019, LopezAcosta2019Tiling, Watkins2025GitHub\nusing Images: erode, segment_mean, labels_map, SegmentedImage, RGB, mosaicview\n","category":"section"},{"location":"tutorials/lopez-acosta-2019-workflow/#Load-the-images","page":"Segmentation Algorithm Workflows","title":"Load the images","text":"Load the dataset from https://github.com/danielmwatkins/icefloevalidation_dataset using the Watkins2025GitHub data loader.\n\n\ndata_loader = Watkins2025GitHub(; ref=\"a451cd5e62a10309a9640fbbe6b32a236fcebc70\")\n\n\nThe available data are listed in the metadata field:\n\n\nfirst(data_loader().metadata, 10)\n\n\nFor the example, we choose a single case from Baffin Bay in May 2022.\n\n\ndataset = data_loader(c-> c.case_number == 6 && c.satellite == \"terra\")\ncase = first(dataset)\n\n\nThe data include the true-color image:\n\n\ntruecolor = RGB.(case.modis_truecolor) # TODO: remove RGB cast\n\n\n... a false-color image:\n\n\nfalsecolor = RGB.(case.modis_falsecolor) # TODO: remove RGB cast\n\n\n... and a landmask, which in this particular case is empty:\n\n\nlandmask = RGB.(case.modis_landmask) # TODO: remove RGB cast\n","category":"section"},{"location":"tutorials/lopez-acosta-2019-workflow/#Run-the-segmentation-algorithm","page":"Segmentation Algorithm Workflows","title":"Run the segmentation algorithm","text":"The segmentation algorithm is an object with parameters as follows:\n\n\nsegmentation_algorithm = LopezAcosta2019.Segment()\n\n\nIf we wanted to modify the options, we could include those in the call above.  See the documentation for LopezAcosta2019.Segment for details. The default parameters are as follows:\n\n\ndump(segmentation_algorithm)\n\n\nRun the algorithm as follows:\n\n\nsegments = segmentation_algorithm(truecolor, falsecolor, landmask)\n\n\nTo show the results with each segment marked using its mean color:\n\n\nmap(i -> segment_mean(segments, i), labels_map(segments))\n\n\nWe can do the same with the falsecolor image:\n\n\n# Get the labels_map\nsegments_falsecolor = SegmentedImage(falsecolor, labels_map(segments))\nmap(i -> segment_mean(segments_falsecolor, i), labels_map(segments_falsecolor))\n\n\nLet's compare the segmented output to the manually validated labels:\n\n\nman_labels = case.validated_binary_floes\noutlines = man_labels .- erode(man_labels)\nseg_vs = map(i -> segment_mean(segments, i), labels_map(segments))\nmosaicview(truecolor, seg_vs .* (1 .- Float64.(outlines)), nrow=1)\n","category":"section"},{"location":"tutorials/lopez-acosta-2019-workflow/#Run-the-segmentation-algorithm-with-tiling","page":"Segmentation Algorithm Workflows","title":"Run the segmentation algorithm with tiling","text":"The \"tiling\" version of the algorithm is an object:\n\n\nsegmentation_algorithm_with_tiling = LopezAcosta2019Tiling.Segment()\n\n\nIt has more configurable parameters.  For details, see the documentation of LopezAcosta2019Tiling.Segment. The default parameters are as follows:\n\n\ndump(segmentation_algorithm_with_tiling)\n\n\n\nsegments = segmentation_algorithm_with_tiling(truecolor, falsecolor, landmask)\n\n\nTo show the results with each segment marked using its mean color:\n\n\nmap(i -> segment_mean(segments, i), labels_map(segments))\n\n\nWith the falsecolor image:\n\n\n# Get the labels_map\nsegments_falsecolor = SegmentedImage(falsecolor, labels_map(segments))\nmap(i -> segment_mean(segments_falsecolor, i), labels_map(segments_falsecolor))\n\n\nLet's compare the segmented output to the manually validated labels:\n\n\nman_labels = case.validated_binary_floes\noutlines = man_labels .- erode(man_labels)\nseg_vs = map(i -> segment_mean(segments, i), labels_map(segments))\nmosaicview(truecolor, seg_vs .* (1 .- Float64.(outlines)), nrow=1)\n","category":"section"},{"location":"preprocessing/#Preprocessing","page":"Preprocessing","title":"Preprocessing","text":"IFT operates on optical satellite imagery. The main functions are designed with \"true color\" and \"false color\" imagery in mind, and have thus far primarily been tested on imagery from the Moderate Resolution Imaging Spectroradiometer (MODIS) from the NASA Aqua and Terra satellites. The preprocessing routines mask land and cloud features, and aim to adjust and sharpen the remainder of the images to amplify the contrast along the edges of sea ice floes. The functions use three different images: a land mask, a true color image, and a false color image. Examples are based on the NASA MODIS dataset.","category":"section"},{"location":"preprocessing/#Land-masks","page":"Preprocessing","title":"Land masks","text":"Landmask generation and dilation is handled by the function create_landmask. Landmask images from file are loaded as RGB matrices. This example uses an image from NASA EarthData landmask for Beaufort Sea.\n\nusing IceFloeTracker\n\nrgb_landmask = IceFloeTracker.load(<landmask_path>);\nlandmask_imgs = IceFloeTracker.create_landmask(rgb_landmask);\n\nThe landmask_imgs object includes a binary version of the original landmask and a dilated version, which helps to cover the complicated near-coastal regions.\n\n<img src=\"../assets/landmask_example.png\" width=\"600\" alt=\"Landmask Example\"/>\n\nAt the top, we have the original landmask TIFF, which has black and gray values. The middle image is the binary image, with land set to 0. At the bottom, we can see the dilated image using the default value of the structuring element. The default has radius 50, which results in a coastal mask of 12.5 km based on the 250 m pixel size of default MODIS imagery.","category":"section"},{"location":"preprocessing/#Cloud-masks","page":"Preprocessing","title":"Cloud masks","text":"Setting thresholds for cloud mask","category":"section"},{"location":"preprocessing/#Image-regularization","page":"Preprocessing","title":"Image regularization","text":"","category":"section"},{"location":"tutorials/segmentation-tracking/","page":"Segmentation and Tracking using IceFloeTracker.jl","title":"Segmentation and Tracking using IceFloeTracker.jl","text":"(Image: Open this notebook in Colab)","category":"section"},{"location":"tutorials/segmentation-tracking/#Segmentation-and-Tracking-using-IceFloeTracker.jl","page":"Segmentation and Tracking using IceFloeTracker.jl","title":"Segmentation and Tracking using IceFloeTracker.jl","text":"\n# Setup environment\nusing Pkg\nPkg.add(;name=\"IceFloeTracker\", rev=\"826/merge\")\nPkg.add(\"Images\")\n\n\n\n# Load packages\nusing IceFloeTracker: LopezAcosta2019Tiling, Watkins2025GitHub, FloeTracker, ChainedFilterFunction, MinimumWeightMatchingFunction\nusing Images: erode, segment_mean, labels_map, SegmentedImage, RGB, mosaicview\nusing Dates: DateTime\n\n\n\ndata_loader = Watkins2025GitHub(; ref=\"a451cd5e62a10309a9640fbbe6b32a236fcebc70\")\ncases = data_loader(c -> c.case_number == 6)\nmosaicview([c.modis_truecolor for c in cases], nrow=1)\n\n\n\nsegmenter = LopezAcosta2019Tiling.Segment()\nsegmentation_results = [segmenter(c.modis_truecolor, c.modis_falsecolor, c.modis_landmask) for c in cases]\n\n\nTODO: would one of these be a better interface?\n\nsegmentation_results = segmenter.(cases.modis_truecolor, cases.modis_falsecolor, cases.modis_landmask)\nsegmentation_results = segmenter(cases.modis_truecolor, cases.modis_falsecolor, cases.modis_landmask)\n\nWould require:\n\ndefining broadcasting for the Dataset struct\ndefining broadcasting for the Segment interface\n\n\ntracker = FloeTracker(\n    filter_function=ChainedFilterFunction(), \n    matching_function=MinimumWeightMatchingFunction()\n)\ntracking_results = tracker(segmentation_results, DateTime.(cases.metadata.start_date))\n\n\nTODO: would one of these be a better interface?\n\ntracking_results = tracker(segmentation_results, cases.metadata.passtime) TODO: rename start_date to passtime in validation data set\n\n\n\n","category":"section"},{"location":"#IceFloeTracker.jl","page":"IceFloeTracker.jl","title":"IceFloeTracker.jl","text":"","category":"section"},{"location":"#Overview","page":"IceFloeTracker.jl","title":"Overview","text":"IceFloeTracker.jl is a collection of routines and tools for processing remote sensing imagery, identifying sea ice floes, and tracking the displacement and rotation of ice floes across multiple images. It can be used either standalone to create custom processing pathways or with the Ice Floe Tracker Pipeline.\n\n","category":"section"},{"location":"#Algorithm-components","page":"IceFloeTracker.jl","title":"Algorithm components","text":"The Ice Floe Tracker (IFT) package includes the core functions for the three main steps of the algorithm. These functions can be used independently and can be customized for specific use cases. ","category":"section"},{"location":"#Preprocessing","page":"IceFloeTracker.jl","title":"Preprocessing","text":"IFT operates on optical satellite imagery. The main functions are designed with \"true color\" and \"false color\" imagery in mind, and have thus far primarily been tested on imagery from the Moderate Resolution Imaging Spectroradiometer (MODIS) from the NASA Aqua and Terra satellites. The preprocessing routines mask land and cloud features, and aim to adjust and sharpen the remainder of the images to amplify the contrast along the edges of sea ice floes. (TBD: Link to main preprocessing page)","category":"section"},{"location":"#Segmentation","page":"IceFloeTracker.jl","title":"Segmentation","text":"The IFT segmentation functions include functions for semantic segmentation (pixel-by-pixel assignment into predefined categories) and object-based segmentation (groupings of pixels into distinct objects). The semantic segmentation steps use k-means to group pixels into water and ice regions. A combination of watershed functions, morphological operations, and further applications of k-means are used to identify candidate ice floes. (TBD: Link to main segmentation page)","category":"section"},{"location":"#Tracking","page":"IceFloeTracker.jl","title":"Tracking","text":"Ice floe tracking is carried out by comparing the shapes produced in the segmentation step. Shapes with similar area are rotated until the difference in surface area is minimized, and then the edge shapes are compared using a Ѱ-s curve. If thresholds for correlation and area differences are met, then the floe with the best correlation and smallest area differences are considered matches and the objects are assigned the same label. In the end, trajectories for individual floes are recorded in a dataframe.","category":"section"},{"location":"#Developers","page":"IceFloeTracker.jl","title":"Developers","text":"IceFloeTracker.jl is a product of the Wilhelmus Lab at Brown University, led by Monica M. Wilhelmus. The original algorithm was developed by Rosalinda Lopez-Acosta during her PhD work at University of California Riverside, advised by Dr. Wilhelmus. The translation of the original Matlab code into the current modular, open source Julia package has been carried out in conjunction with the Center for Computing and Visualization at Brown University. Contributors include Daniel Watkins, Maria Isabel Restrepo, Carlos Paniagua, Tim Divoll, John Holland, and Bradford Roarr.","category":"section"},{"location":"#Citing","page":"IceFloeTracker.jl","title":"Citing","text":"If you use IceFloeTracker.jl in research, teaching, or elsewhere, please mention the IceFloeTracker package and cite our journal article outlining the algorithm:\n\nLopez-Acosta et al., (2019). Ice Floe Tracker: An algorithm to automatically retrieve Lagrangian trajectories via feature matching from moderate-resolution visual imagery. Remote Sensing of Environment, 234(111406), doi:10.1016/j.rse.2019.111406.","category":"section"},{"location":"#Papers-using-Ice-Floe-Tracker","page":"IceFloeTracker.jl","title":"Papers using Ice Floe Tracker","text":"Manucharyan, Lopez-Acosta, and Wilhelmus (2022)*. Spinning ice floes reveal intensification of mesoscale eddies in the western Arctic Ocean. Scientific Reports, 12(7070), doi:10.1038/s41598-022-10712-z\nWatkins, Bliss, Hutchings, and Wilhelmus (2023)*. Evidence of Abrupt Transitions Between Sea Ice Dynamical Regimes in the East Greenland Marginal Ice Zone. Geophysical Research Letters, 50(e2023GL103558), pp. 1-10, doi:10.1029/2023GL103558\n\n*Papers using data from the Matlab implementation of Ice Floe Tracker.","category":"section"},{"location":"#API-Reference","page":"IceFloeTracker.jl","title":"API Reference","text":"","category":"section"},{"location":"#Index","page":"IceFloeTracker.jl","title":"Index","text":"","category":"section"},{"location":"#IceFloeTracker.Segmentation.IceDetectionAlgorithm","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.IceDetectionAlgorithm","text":"IceDetectionAlgorithm\n\nFunctors to detect ice regions in an image.\n\nEach algorithm a with parameters kwargs... can be called like:\n\nbinarize(image, a(; kwargs...)) \nor a(; kwargs...)(image).\n\n\n\n\n\n","category":"type"},{"location":"#IceFloeTracker.Segmentation.IceDetectionBrightnessPeaksMODIS721","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.IceDetectionBrightnessPeaksMODIS721","text":"IceDetectionBrightnessPeaksMODIS721(;\n    band_7_threshold::Real,\n    possible_ice_threshold::Real\n)(image)\nbinarize(\n    modis_721_image, \n    a::IceDetectionBrightnessPeaksMODIS721\n)\n\nReturns pixels for a MODIS image where (band7 < threshold AND both (band2, band_1) are are above a peak value above some threshold).\n\n\n\n\n\n","category":"type"},{"location":"#IceFloeTracker.Segmentation.IceDetectionFirstNonZeroAlgorithm","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.IceDetectionFirstNonZeroAlgorithm","text":"IceDetectionFirstNonZeroAlgorithm(;\n    algorithms::Vector{IceDetectionAlgorithm},\n)(image)\nbinarize(image, algorithms::IceDetectionFirstNonZeroAlgorithm)\n\nRuns each algorithm from algorithms on the image, and returns the first which detects any ice.\n\n\n\n\n\n","category":"type"},{"location":"#IceFloeTracker.Segmentation.IceDetectionThresholdMODIS721","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.IceDetectionThresholdMODIS721","text":"IceDetectionThresholdMODIS721(;\n    band_7_threshold::Real,\n    band_2_threshold::Real,\n    band_1_threshold::Real,\n)(image)\nbinarize(\n    modis_721_image, \n    a::IceDetectionThresholdMODIS721\n)\n\nReturns pixels for a MODIS image where (band7 < threshold AND band2 > threshold AND band_1 > threshold).\n\n\n\n\n\n","category":"type"},{"location":"#IceFloeTracker.Segmentation.SegmentationComparison","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.SegmentationComparison","text":"Results of a segmentation comparison\n\n\n\n\n\n","category":"type"},{"location":"#IceFloeTracker.Segmentation.SegmentationSummary","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.SegmentationSummary","text":"Results of a segmentation comparison\n\n\n\n\n\n","category":"type"},{"location":"#IceFloeTracker.Segmentation.IceDetectionLopezAcosta2019-Tuple{}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.IceDetectionLopezAcosta2019","text":"IceDetectionLopezAcosta2019(;\n    band_7_threshold::Float64=Float64(5 / 255),\n    band_2_threshold::Float64=Float64(230 / 255),\n    band_1_threshold::Float64=Float64(240 / 255),\n    band_7_threshold_relaxed::Float64=Float64(10 / 255),\n    band_1_threshold_relaxed::Float64=Float64(190 / 255),\n    possible_ice_threshold::Float64=Float64(75 / 255),\n)\n\nReturns the first non-zero result of two threshold-based and one brightness-peak based ice detections.\n\nDefault thresholds are defined in the published Ice Floe Tracker article: Remote Sensing of the Environment 234 (2019) 111406.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Segmentation.addlatlon!-Tuple{DataFrames.DataFrame, AbstractString}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.addlatlon!","text":"addlatlon(pairedfloesdf::DataFrame, refimage::AbstractString)\n\nAdd columns latitude, longitude, and pixel coordinates x, y to pairedfloesdf.\n\nArguments\n\npairedfloesdf: dataframe containing floe tracking data.\nrefimage: path to reference image.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Segmentation.binarize_segments-Tuple{ImageSegmentation.SegmentedImage}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.binarize_segments","text":"Find pixels in a segmented image with non-zero labels\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Segmentation.convertcentroid!-Tuple{Any, Any, Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.convertcentroid!","text":"convertcentroid!(propdf, latlondata, colstodrop)\n\nConvert the centroid coordinates from row and column to latitude and longitude dropping unwanted columns specified in colstodrop for the output data structure. Addionally, add columns x and y with the pixel coordinates of the centroid.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Segmentation.converttounits!-Tuple{Any, Any, Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.converttounits!","text":"converttounits!(propdf, latlondata, colstodrop)\n\nConvert the floe properties from pixels to kilometers and square kilometers where appropiate. Also drop the columns specified in colstodrop.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Segmentation.find_ice_labels-Tuple{Matrix{ColorTypes.RGB{Float64}}, BitMatrix}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.find_ice_labels","text":"find_ice_labels(falsecolor_image, landmask; band_7_threshold, band_2_threshold, band_1_threshold, band_7_relaxed_threshold, band_1_relaxed_threshold, possible_ice_threshold)\n\nReturns pixel indices of likely ice from false color reflectance image, using the thresholds from the Ice Floe Tracker article: Remote Sensing of the Environment 234 (2019) 111406.\n\nArguments\n\nfalsecolor_image: corrected reflectance false color image - bands [7,2,1]\nlandmask: bitmatrix landmask for region of interest\nband_7_threshold: threshold value used to identify ice in band 7, N0f8(RGB intensity/255)\nband_2_threshold: threshold value used to identify ice in band 2, N0f8(RGB intensity/255)\nband_1_threshold: threshold value used to identify ice in band 2, N0f8(RGB intensity/255)\nband_7_relaxed_threshold: threshold value used to identify ice in band 7 if not found on first pass, N0f8(RGB intensity/255)\nband_1_relaxed_threshold: threshold value used to identify ice in band 1 if not found on first pass, N0f8(RGB intensity/255)\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Segmentation.get_ice_masks-Tuple{AbstractArray{<:Union{ColorTypes.AbstractRGB, ColorTypes.Transparent3{C} where C<:ColorTypes.AbstractRGB, ColorTypes.TransparentRGB}}, AbstractArray{<:ColorTypes.AbstractGray}, AbstractArray{<:Bool}, AbstractMatrix{Tuple{UnitRange{Int64}, UnitRange{Int64}}}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.get_ice_masks","text":"get_ice_masks(\n    falsecolor_image,\n    morph_residue,\n    landmask,\n    tiles,\n    binarize;\n    band_7_threshold,\n    band_2_threshold,\n    band_1_threshold,\n    band_7_threshold_relaxed,\n    band_1_threshold_relaxed,\n    possible_ice_threshold,\n    k\n)\n\nIdentifies potential sea ice floes using two methods: selection of a relevant k-means cluster and application of adaptive threshold binarization. For the k-means section, a series of thresholds on band 7, 2, and 1 reflectance  are applied in order to find the cluster containing bright sea ice pixels.\n\nArguments\n\nfalsecolor_image: MODIS False Color Bands 7-2-1.\nmorph_residue: Grayscale sharpened and equalized image from preprocessing workflow.\nlandmask: Binary landmask. \ntiles: Iterable with tile divisions.\nbinarize::Bool=true: Whether to binarize the tiling.\nband_7_threshold=5/255: The threshold for band 7.\nband_2_threshold=230/255: The threshold for band 2.\nband_1_threshold=240/255: The threshold for band 1.\nband_7_threshold_relaxed=10: The relaxed threshold for band 7.\nband_1_threshold_relaxed=190: The relaxed threshold for band 1.\npossible_ice_threshold=75/255: The threshold for possible ice.\nk=4: The number of clusters to use for k-means segmentation.\n\nReturns\n\nBinary image with likely sea ice floes = 1.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Segmentation.get_ice_peaks-Tuple{Any, Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.get_ice_peaks","text":"Given the edges and counts from build_histogram, identify local maxima and return the location of the largest local maximum that is bright enough that it is possibly sea ice. Locations are determined by  the edges, which by default are the left bin edges. Note also that peaks defaults to the left side of plateaus. Returns Inf if there are no non-zero parts of the histogram with bins larger than the possible ice threshold, or if there are no detected peaks larger than the minimum prominence.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Segmentation.kmeans_segmentation","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.kmeans_segmentation","text":"kmeans_segmentation(gray_image, ice_labels;)\n\nApply k-means segmentation to a gray image to isolate a cluster group representing sea ice. Returns a binary image with ice segmented from background.\n\nArguments\n\ngray_image: output image from ice-water-discrimination.jl or gray ice floe leads image in segmentation_f.jl\nice_labels: vector if pixel coordinates output from find_ice_labels.jl\n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Segmentation.regionprops","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.regionprops","text":"regionprops(label_img, ; properties, connectivity)\n\nA wrapper of the regionprops function from the skimage python library.\n\nSee its full documentation at https://scikit-image.org/docs/stable/api/skimage.measure.html#skimage.measure.regionprops.\n\nArguments\n\nlabel_img: Image with the labeled objects of interest\nintensity_img: (Optional) Used for generating extra_properties, integer/float array from which (presumably) label_img was generated\nextra_properties: (Optional) not yet implemented. It will be set to nothing\n\nSee also regionprops_table\n\nExamples\n\njulia> Random.seed!(123);\n\njulia> bw_img = rand([0, 1], 5, 10)\n5×10 Matrix{Int64}:\n 1  0  1  0  0  0  0  0  0  1\n 1  0  1  1  1  0  0  0  1  1\n 1  1  0  1  1  0  1  0  0  1\n 0  1  0  1  0  0  0  0  1  0\n 1  0  0  0  0  1  0  1  0  1\n\n julia> label_img = Images.label_components(bw_img, trues(3,3))\n 5×10 Matrix{Int64}:\n  1  0  1  0  0  0  0  0  0  4\n  1  0  1  1  1  0  0  0  4  4\n  1  1  0  1  1  0  3  0  0  4\n  0  1  0  1  0  0  0  0  4  0\n  1  0  0  0  0  2  0  4  0  4\n\n julia> regions = regionprops(label_img, bw_img);\n\n julia> for region in regions\n           println(region.area,\"\t\", region.perimeter)\n        end\n13      11.621320343559642\n1       0.0\n1       0.0\n7       4.621320343559642\n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Segmentation.regionprops_table","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.regionprops_table","text":"regionprops_table(label_img, intensity_img; properties, connectivity, extra_properties)\n\nA wrapper of the regionprops_table function from the skimage python library.\n\nSee its full documentation at https://scikit-image.org/docs/stable/api/skimage.measure.html#regionprops-table.\n\nArguments\n\nlabel_img: Image with the labeled objects of interest\nintensity_img: (Optional) Used for generating extra_properties, integer/float array from which (presumably) label_img was generated \nproperties: List (Vector or Tuple) of properties to be generated for each connected component in label_img\nextra_properties: (Optional) not yet implemented. It will be set to nothing\n\nNotes\n\nZero indexing has been corrected for the bbox and centroid properties\nbbox data (max_col and max_row) are inclusive\ncentroid data are rounded to the nearest integer\n\nSee also regionprops\n\nExamples\n\njulia> using IceFloeTracker, Random, Images\n\njulia> Random.seed!(123);\n\njulia> bw_img = rand([0, 1], 5, 10)\n5×10 Matrix{Int64}:\n 1  0  1  0  0  0  0  0  0  1\n 1  0  1  1  1  0  0  0  1  1\n 1  1  0  1  1  0  1  0  0  1\n 0  1  0  1  0  0  0  0  1  0\n 1  0  0  0  0  1  0  1  0  1\n\njulia> label_img = label_components(bw_img, trues(3,3))\n5×10 Matrix{Int64}:\n 1  0  1  0  0  0  0  0  0  4\n 1  0  1  1  1  0  0  0  4  4\n 1  1  0  1  1  0  3  0  0  4\n 0  1  0  1  0  0  0  0  4  0\n 1  0  0  0  0  2  0  4  0  4\n\njulia> properties = [\"area\", \"perimeter\"]\n2-element Vector{String}:\n \"area\"\n \"perimeter\"\n\n julia> regionprops_table(label_img, bw_img, properties = properties)\n 4×2 DataFrame\n  Row │ area   perimeter \n      │ Int32  Float64   \n ─────┼──────────────────\n    1 │    13   11.6213\n    2 │     1    0.0\n    3 │     1    0.0\n    4 │     7    4.62132\n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Segmentation.segmentation_comparison-Tuple{Union{Nothing, ImageSegmentation.SegmentedImage}, Union{Nothing, ImageSegmentation.SegmentedImage}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.segmentation_comparison","text":"function segmentationcomparison(     validated::SegmentedImage, measured::SegmentedImage )::@NamedTuple{recall::Real, precision::Real, Fscore::Real}\n\nCompares two SegmentedImages and returns values describing how similar the segmentations are.\n\nThis treats the segment labeled 0 as background.\n\nMeasures:\n\nprecision: rate at which pixels in validated segments belong to measured segments\nrecall: rate at which pixels in measured segments belong to validated segments\nF_score: harmonic mean of precision and recall\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Segmentation.tiled_adaptive_binarization-Tuple{Any, Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.tiled_adaptive_binarization","text":"tiledadaptivebinarization(img, tiles; minimumwindowsize=). \n\nApplies the (AdaptiveThreshold)[https://juliaimages.org/ImageBinarization.jl/v0.1/#Adaptive-Threshold-1] binarization algorithm\nto each tile in the image. Following the recommendations from ImageBinarization, the default is to use the integer window size\nnearest to 1/8th the tile size if the tile is large enough. So that the window is large enough to include moderately large floes,\nthe default minimum window size is 100 pixels (25 km for MODIS imagery). The minimum brightness parameter masks pixels with low\ngrayscale intensity to prevent dark regions from getting brightened (i.e., the center of a large patch of open water).\nThe \"threshold_percentage\" parameter is passed to the the AdaptiveThreshold function (percentage parameter).\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.ChainedFilterFunction","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.ChainedFilterFunction","text":"ChainedFilterFunction(filters::Vector)\n\nCompute the psi-s correlation between a floe and a dataframe of candidate floes. Adds the  psi-s correlation,  psi-s correlation score (1 - correlation), and the result of the threshold function to the columns of candidates. The input is a vector of functions that take a floe and a candidates data frame as inputs. The default is to use seven filter functions with the threshold functions as defined in Watkins et al. 2026. These filters are:     1. DistanceThresholdFilter     2-5. RelativeErrorThresholdFilters for area, convexarea, majoraxislength, and minoraxis_length     6. ShapeDifferenceThresholdFilter     7. PsiSCorrelationThresholdFilter Filters 2-7 use a PiecewiseLinearThresholdFunction.\n\n\n\n\n\n","category":"type"},{"location":"#IceFloeTracker.Tracking.DistanceThresholdFilter","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.DistanceThresholdFilter","text":"DistanceThresholdFilter(time_column, dist_column, threshold_function, threshold_column)\nDistanceThresholdFilter(floe, candidates)\n\nThe distance threshold filter creates columns for time and distance and applies a threshold function to these columns to determine if the net travel is physically possible. The struct is initialized with names for the time and distance columns, the threshold function (a TimeDistanceFunction) and the name of the column in which to store the results. \n\njulia> dt_test = DistanceThresholdFilter(time_colum=:Δt, dist_column=:Δx, threshold_function=LinearTimeDistanceFunction())\n\nNow, let's assume that floe and candidates are already defined. Then\n\njulia> dt_test(floe, candidates)\n\nwill modify candidates in place to include only rows in which the LinearTimeDistanceFunction() evaluates as true.  Passing Val{:raw} as the third argument will forgo the subsetting step so that the output of the test can be examined.\n\n\n\n\n\n","category":"type"},{"location":"#IceFloeTracker.Tracking.MinimumWeightMatchingFunction","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.MinimumWeightMatchingFunction","text":"MinimumWeightMatchingFunction(columns=[:scaled_distance, :relative_error_area, ...])\nMinimumWeightedMatchingFunction(candidate_pairs)\n\nFunction to identify a best matching between pairs of ice floes in the DataFrame candidate_pairs. The columns variable is instantiated by the first functor call and is used to select a list of columns in candidate_pairs to sum. The result of the sum is the weight assigned to each pairing. Then, a best set of unique pairs is found by carrying out two grouped minimizations: first grouping by the first floe, identified by the head_uuid column, and finding the floe with the smallest weight, then grouping by the second floe, identified by the uuid column, and again  finding the floe with the smallest weight. Finally, only pairs that exist in both the forward and backward grouped minizations are identified as likely true matches.\n\n\n\n\n\n","category":"type"},{"location":"#IceFloeTracker.Tracking.PiecewiseLinearThresholdFunction","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.PiecewiseLinearThresholdFunction","text":"The piecewise linear threshold function is defined using two (area, value) pairs. For areas below the minimum area, it is constant at minimum value; likewise for above the maximum area. The threshold function is linear in between these two points. A return  value true indicates that the value is below the threshold. \n\n\n\n\n\n","category":"type"},{"location":"#IceFloeTracker.Tracking.PsiSCorrelationThresholdFilter","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.PsiSCorrelationThresholdFilter","text":"PsiSCorrelationThresholdFunction(area_variable, threshold_column, threshold_function)\nPsiSCorrelationThresholdFunction(floe, candidates, Val(:raw))\n\nCompute the psi-s correlation between a floe and a dataframe of candidate floes. Adds the  psi-s correlation,  psi-s correlation score (1 - correlation), and the result of the threshold function to the columns of candidates.\n\n\n\n\n\n","category":"type"},{"location":"#IceFloeTracker.Tracking.RelativeErrorThresholdFilter","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.RelativeErrorThresholdFilter","text":"RelativeErrorThresholdFilter(variable, area_variable, threshold_column, threshold_function)\nRelativeErrorThresholdFilter(floe, candidates)\nRelativeErrorThresholdFilter(floe, candidates, Var(:raw))\n\nCompute and test (absolute) relative error for variable. The relative error between scalar variables X and Y is defined as \n\nerr = abs(X - Y)/mean(X, Y)\n\nThis function takes a scalar <variable> (which must be a named column in  the candidates DataFrame) and computes the relative error. Calling the function with  the variable name, area_variable, threshold_column name, and athresholdfunctioninitializes the function and saves the parameter values. Once initialized, the function  takes a floe (DataFrameRow) and a DataFrame of candidate floes as arguments, and subsets the candidates to only those which evaluate as true using thethresholdfunction. Including the dummy variableVar(:raw)` returns the candidates dataframe with the test  results without subsetting it.\n\n\n\n\n\n","category":"type"},{"location":"#IceFloeTracker.Tracking.ShapeDifferenceThresholdFilter","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.ShapeDifferenceThresholdFilter","text":"ShapeDifferenceThresholdFilter(area_variable, scale_by, threshold_column, threshold_function)\nShapeDifferenceThresholdFilter(floe, candidates)\nShapeDifferenceThresholdFilter(floe, candidates, Val(:raw))\n\nCompute and test the scaled shape difference between input floe and each floe in the dataframe candidates. Assumes that the shape difference test operates on the shape difference scaled by a variable scale_by and the shape difference test depends on the area. \n\n\n\n\n\n","category":"type"},{"location":"#IceFloeTracker.Tracking.StepwiseLinearThresholdFunction","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.StepwiseLinearThresholdFunction","text":"The stepwise linear threshold function is defined using a changepoint area and two levels.  If the area is less than the changepoint area, the function returns true if the value is below low_value and false otherwsie; if the area is greater than or equal to the changepoint area,  then the value is tested againg high_value.\n\n\n\n\n\n","category":"type"},{"location":"#IceFloeTracker.Tracking.add_floemasks!-Tuple{DataFrames.DataFrame, Union{BitMatrix, Matrix{<:Integer}}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.add_floemasks!","text":"add_floemasks!(props::DataFrame, floeimg::FloeLabelsImage)\nadd_floemasks!.(props::Vector{DataFrame}, floeimgs::Vector{FloeLabelsImage})\n\nAdd a column to props called floearray containing the cropped floe masks from floeimg.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.add_passtimes!-Tuple{Any, Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.add_passtimes!","text":"add_passtimes!(props, passtimes)\n\nAdd a column passtime to each DataFrame in props containing the time of the image in which the floes were captured.\n\nArguments\n\nprops: array of DataFrames containing floe properties.\npasstimes: array of DateTime objects containing the time of the image in which the floes were captured.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.add_uuids!-Tuple{DataFrames.DataFrame}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.add_uuids!","text":"adduuid!(df::DataFrame)\nadduuid!(dfs::Vector{DataFrame})\n\nAssign a unique ID to each floe in a (vector of) table(s) of floe properties.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.add_ψs!-Tuple{DataFrames.DataFrame}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.add_ψs!","text":"addψs!(props_df::DataFrame})\n\nAdd the ψ-s curves to each row of props_df.\n\nNote: each member of props must have a mask column with a binary image representing the floe.  To add floe masks see addfloemasks!.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.add_ψs!-Tuple{Vector{DataFrames.DataFrame}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.add_ψs!","text":"addψs!(props::Vector{DataFrame})\n\nAdd the ψ-s curves to each member of props.\n\nNote: each member of props must have a mask column with a binary image representing the floe.  To add floe masks see addfloemasks!.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.align_centroids-Tuple{AbstractArray{Bool}, AbstractArray{Bool}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.align_centroids","text":"Align images by padding so that the centroids of each image are on the edge of or within the same pixel.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.buildψs-Tuple{AbstractArray}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.buildψs","text":"buildψs(floe_mask)\n\nAlternate method of buildψs accepting binary floe mask as input.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.buildψs-Tuple{Matrix{<:Number}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.buildψs","text":"buildψs(XY::Matrix{<:Number};rangeout::Bool=true,\nunwrap::Bool=true)\n\nAlternate method of buildψs accepting input vectors x and y as a 2-column matrix [x y].\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.buildψs-Tuple{Vector{<:Number}, Vector{<:Number}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.buildψs","text":"buildψs(x::Vector{<:Number},\n           y::Vector{<:Number};\n           rangeout::Bool=true,\n           unwrap::Bool=true)::Tuple{Vector{Float64}, Vector{Float64}}\n\nBuilds the ψ-s curve defined by vectors x and y.\n\nReturns a tuple of vectors with the phases ψ in the first component and the traversed arclength in the second component. \n\nFollowing the convention in [1], the wrapped ψ-s curve has values in [0, 2π) by default; use rangeout to control this behavior.\n\nSee also bwtraceboundary, resample_boundary\n\nArguments\n\nx: Vector of x-coordinates\ny: corresponding vector of y-coordinates\nrangeout: true (default) for phase values in [0, 2π); false for phase values in (-π, π].\nunwrap: set to true to get \"unwrapped\" phases (default). \n\nReference\n\n[1] McConnell, Ross, et al. \"psi-s correlation and dynamic time warping: two methods for tracking ice floes in SAR images.\" IEEE Transactions on Geoscience and Remote sensing 29.6 (1991): 1004-1012.\n\nExample\n\nThe example below builds a cardioid and obtains its ψ-s curve.\n\njulia> t = range(0,2pi,201);\n\njulia> x = @. cos(t)*(1-cos(t));\n\njulia> y = @. sin(t)*(1-cos(t));\n\njulia> plot(x,y) # visualize the cardioid\n\njulia> psi, s = buildψs(x,y);\n\njulia> [s psi] # inspect psi-s data\n200×2 Matrix{Float64}:\n 0.00049344  0.0314159\n 0.0019736   0.0733034\n 0.00444011  0.11938\n 0.00789238  0.166055\n 0.0123296   0.212929\n 0.0177505   0.259894\n 0.024154    0.306907\n 0.0315383   0.35395\n 0.0399017   0.401012\n 0.0492421   0.448087\n ⋮\n 7.96772     9.02377\n 7.97511     9.07083\n 7.98151     9.11787\n 7.98693     9.16488\n 7.99137     9.21185\n 7.99482     9.25872\n 7.99729     9.3054\n 7.99877     9.35147\n 7.99926     9.39336\n\n julia> plot(s, psi) # inspect psi-s curve -- should be a straight line from (0, 0) to (8, 3π)\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.bwtraceboundary-Union{Tuple{Union{Matrix{Float64}, Matrix{Int64}, Matrix{UInt8}, T}}, Tuple{T}} where T<:AbstractMatrix{Bool}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.bwtraceboundary","text":"bwtraceboundary(image::Union{Matrix{Int64},Matrix{Float64},T};\n                P0::Union{Tuple{Int,Int},CartesianIndex{2},Nothing}=nothing,\n                closed::Bool=true) where T<:AbstractMatrix{Bool}\n\nTrace the boundary of objects in image \n\nBackground pixels are represented as zero. The algorithm traces the boundary counterclockwise and an initial point P0 can be specified. If more than one boundary is detected and an initial point is provided, the boundary that contains this point is returned as a vector of CartesianIndex types. Otherwise an array of vectors is returned with all the detected boundaries in image. \n\nArguments\n\nimage: image, preferably binary with one single object, whose objects' boundaries are to be traced.\nP0: initial point of a target boundary.\nclosed: if true (default) makes the inital point of a boundary equal to the last point.\n\nExample\n\njulia> A = zeros(Int, 13, 16); A[2:6, 2:6] .= 1; A[4:8, 7:10] .= 1; A[10:12,13:15] .= 1; A[10:12,3:6] .= 1;\n\njulia> A\n13×16 Matrix{Int64}:\n 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n 0  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0\n 0  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0\n 0  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0\n 0  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0\n 0  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0\n 0  0  0  0  0  0  1  1  1  1  0  0  0  0  0  0\n 0  0  0  0  0  0  1  1  1  1  0  0  0  0  0  0\n 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n 0  0  1  1  1  1  0  0  0  0  0  0  1  1  1  0\n 0  0  1  1  1  1  0  0  0  0  0  0  1  1  1  0\n 0  0  1  1  1  1  0  0  0  0  0  0  1  1  1  0\n 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n\njulia> boundary = IceFloeTracker.bwtraceboundary(A);\n\njulia> boundary[3]\n9-element Vector{CartesianIndex}:\n CartesianIndex(10, 13)\n CartesianIndex(11, 13)\n CartesianIndex(12, 13)\n CartesianIndex(12, 14)\n CartesianIndex(12, 15)\n CartesianIndex(11, 15)\n CartesianIndex(10, 15)\n CartesianIndex(10, 14)\n CartesianIndex(10, 13)\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.compute_centroid-Tuple{AbstractArray{Bool}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.compute_centroid","text":"Calculate the centroid of a binary image. If 'rounded', return the nearest integer.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.cropfloe-Tuple{Union{BitMatrix, Matrix{<:Integer}}, DataFrames.DataFrame, Integer}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.cropfloe","text":"cropfloe(floesimg, props, i)\n\nCrops the floe delimited by the bounding box data in props at index i from the floe image floesimg.\n\nIf the dataframe has bounding box data min_row, min_col, max_row, max_col, but no label, then returns the largest contiguous component.\n\nIf the dataframe has bounding box data min_row, min_col, max_row, max_col, and a label, then returns the component with the label. In this case, floesimg must be an Array{Int}.\n\nIf the dataframe has only a label and no bounding box data, then returns the component with the label, padded by one cell of zeroes on all sides. In this case, floesimg must be an Array{Int}.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.cropfloe-Union{Tuple{I}, Tuple{BitMatrix, Vararg{I, 4}}} where I<:Integer","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.cropfloe","text":"cropfloe(floesimg, min_row, min_col, max_row, max_col)\n\nCrops the floe delimited by min_row, min_col, max_row, max_col, from the floe image floesimg.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.cropfloe-Union{Tuple{J}, Tuple{I}, Tuple{Matrix{I}, J, J, J, J, I}} where {I<:Integer, J<:Integer}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.cropfloe","text":"cropfloe(floesimg, min_row, min_col, max_row, max_col, label)\n\nCrops the floe from floesimg with the label label, returning the region bounded by min_row, min_col, max_row, max_col, and converting to a BitMatrix.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.crosscorr-Union{Tuple{T}, Tuple{Vector{T}, Vector{T}}} where T<:Real","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.crosscorr","text":"r, lags = crosscorr(u::Vector{T},\n                    v::Vector{T};\n                    normalize::Bool=false,\n                    padmode::Symbol=:longest)\n\nWrapper of DSP.xcorr with normalization (see https://docs.juliadsp.org/stable/convolutions/#DSP.xcorr)\n\nReturns the pair (r, lags) with the cross correlation scores r and corresponding lags according to padmode.\n\nArguments\n\nu,v: real vectors which could have unequal length.\nnormalize: return normalized correlation scores (false by default).\npadmode: either :longest (default) or :none to control padding of shorter vector with zeros.\n\nExamples\n\nThe example below builds two vectors, one a shifted version of the other, and computes various cross correlation scores.\n\njulia> n = 1:5;\n\njulia> x = 0.48.^n;\n\njulia> y = circshift(x,3);\n\njulia> r, lags = crosscorr(x,y,normalize=true);\n\njulia> [r lags]\n9×2 Matrix{Float64}:\n0.369648    -4.0\n0.947531    -3.0\n0.495695    -2.0\n0.3231      -1.0\n0.332519     0.0\n0.15019      1.0\n0.052469     2.0\n0.0241435    3.0\n0.00941878   4.0\n\njulia> r, lags = crosscorr(x,y,normalize=true,padmode=:none);\n\njulia> [r lags]\n9×2 Matrix{Float64}:\n0.369648    1.0\n0.947531    2.0\n0.495695    3.0\n0.3231      4.0\n0.332519    5.0\n0.15019     6.0\n0.052469    7.0\n0.0241435   8.0\n0.00941878  9.0\n\nThis final example builds two vectors of different length and computes some cross correlation scores.\n\njulia> n = 1:5; m = 1:3;\n\njulia> x = 0.48.^n; y = 0.48.^m;\n\njulia> r, lags = crosscorr(x,y,normalize=true);\n\njulia> [r lags]\n9×2 Matrix{Float64}:\n0.0          -4.0\n4.14728e-17  -3.0\n0.178468     -2.0\n0.457473     -1.0\n0.994189      0.0\n0.477211      1.0\n0.229061      2.0\n0.105402      3.0\n0.0411191     4.0\n\njulia> r, lags = crosscorr(x,y,normalize=true,padmode=:none);\n\njulia> [r lags]\n7×2 Matrix{Float64}:\n0.178468   1.0\n0.457473   2.0\n0.994189   3.0\n0.477211   4.0\n0.229061   5.0\n0.105402   6.0\n0.0411191  7.0\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.floe_tracker-Tuple{Vector{DataFrames.DataFrame}, Any, Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.floe_tracker","text":"floe_tracker(props; filter_function, matching_function, minimum_floe_size, maximum_floe_size, maximum_time_step)\n\nTrack ice floes over multiple observations.\n\nTrajectories are built as follows:\n\nAssume the floes detected in observation 1 are trajectories of length 1.\nFor each subsequent observation at time t`:\nDetermine the latest observation for each trajectory – these are the \"current trajectory heads\".\nSelect the subset of trajectory heads observed within the window maximum_time_step, t\nApply the filter function in order to determine possible floe pairings \nApply the matching function to produce unique pairs of floes\nUpdate the trajectories to include the newly paired floes\nAdd all unmatched floes as heads for new trajectories.\n\nArguments\n\nprops::Vector{DataFrame}: A vector of DataFrames, each containing ice floe properties for a single observation time. Each DataFrame must have the following columns:\n\"area\"\n\"min_row\"\n\"min_col\"\n\"max_row\"\n\"max_col\"\n\"row_centroid\"\n\"col_centroid\"\n\"convex_area\"\n\"majoraxislength\"\n\"minoraxislength\"\n\"orientation\"\n\"perimeter\"\n\"mask\": 2D boolean floe image cropped to the floe location\n\"passtime\": A timestamp for the floe\n\"psi\": the psi-s curve for the floe\n\"uuid\": a universally unique identifier for each segmented floe\nfilter_function: A function that accepts a floe::DataFrameRow and a candidates::DataFrame argument, and subsets the candidates dataframe to those rows that are possible matches for floe.\nmatching_function: A function that takes the dataframe of candidate pairs and resolves conflicts to find at most one match for each floe.\n\nReturns\n\nA DataFrame with the above columns, plus extra columns:\n\ncolumns added by the filter function, such as similarity measures\nhead_uuid, the floe which was best matched by this floe.\nTrajectories are identified by: \na unique identifier ID and the \nUUID of the trajectory, trajectory_uuid.\n\nNote: the props dataframes are modified in place.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.get_rotation_measurements-Tuple{DataFrames.DataFrameRow, DataFrames.DataFrameRow}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.get_rotation_measurements","text":"Calculate the angle and rotation rate between two observations in DataFrameRows row1 and row2. image_column and time_column specify which columns to use from the DataFrameRows. registration_function is used to compare the two images and should return an angle. Returns a NamedTuple with the angle theta_rad, time difference dt_sec and rotation rate omega_rad_per_sec, and the two input rows.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.get_rotation_measurements-Tuple{DataFrames.DataFrameRow, DataFrames.DataFrame}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.get_rotation_measurements","text":"Calculate the angle and rotation rate between a measurement in a DataFrameRow measurement, and all the other rows in DataFrame df.\n\nimage_column is the column with the image to compare, \ntime_column is the column with the timepoint of each observation,\nregistration_function is used to compare the two images and should return an angle.\n\nReturns a vector of NamedTuples with one entry for each comparison, with the angle theta_rad, time difference dt_sec and rotation rate omega_rad_per_sec, and the two input rows for each comparison row1 and row2.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.get_rotation_measurements-Tuple{DataFrames.DataFrame}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.get_rotation_measurements","text":"Calculate the angle and rotation rate between observations in DataFrame df.\n\nid_column is the column with the ID of the image over several observations, e.g. the floe ID.\nimage_column is the column with the image to compare, \ntime_column is the column with the timepoint of each observation,\nregistration_function is used to compare the two images and should return an angle.\n\nEach row is compared to each other row in df which are:\n\nfor the same object ID,\nstrictly older,\nnot older than the previous day.\n\nReturns a DataFrame with one row for each comparison, with the angle theta_rad, time difference dt_sec and rotation rate omega_rad_per_sec, and all the other values from df with the column name suffix 1 for the first observation and 2 for the second.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.get_rotation_measurements-Union{Tuple{T}, Tuple{AbstractArray, AbstractArray, T, T}} where T<:Union{Dates.DateTime, TimeZones.ZonedDateTime}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.get_rotation_measurements","text":"Calculate the angle and rotation rate between two images image1 and image2 at times time1 and time2. Returns a NamedTuple with the angle theta_rad, time difference dt_sec and rotation rate omega_rad_per_sec. registration_function is used to compare the two images and should return an angle.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.grad-Tuple{Matrix{<:Number}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.grad","text":"dx, dy = grad(A::Matrix{<:Number})\n\nMake gradient vector field for the set of points with coordinates in the rows of the matrix A with x-coordinates down column 1 and y-coordinates down column 2. Return a tuple with dx and dy in that order. \n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.grad-Tuple{Vector{<:Number}, Vector{<:Number}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.grad","text":"dx, dy = grad(x::Vector{<:Number}, y::Vector{<:Number})\n\nMake gradient vector field for the set of points with coordinates in vectors x and y. Return a tuple with dx and dy in that order. \n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.mismatch","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.mismatch","text":"mismatch(\n    fixed::AbstractArray,\n    moving::AbstractArray,\n    mxrot::Real,\n    step::Real,\n)\n\nEstimate a rotation that minimizes the 'mismatch' of aligning moving with fixed.\n\nReturns a pair with the mismatch score mm and the associated registration angle rot.\n\nArguments\n\nfixed,moving: images to align via a rigid transformation\nmxrot: maximum rotation angle in degrees\nstep: rotation angle step size in degrees\n\nThe default registration angles are evenly distributed in steps of 5º around a full rotation, ensuring that no angles are repeated (since -180º == +180º).\n\nAngles are ordered so that smaller absolute angles which are positive will be returned in the event of a tie in the shape difference. ```\n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Tracking.mismatch-Tuple{AbstractArray, AbstractArray, AbstractArray}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.mismatch","text":"mismatch(\n    fixed::AbstractArray,\n    moving::AbstractArray,\n    test_angles::AbstractArray,\n)\n\nEstimate a rotation that minimizes the 'mismatch' of aligning moving with fixed.\n\nReturns a pair with the mismatch score mm and the associated registration angle rot.\n\nArguments\n\nfixed,moving: images to align via a rigid transformation\ntest_angles: candidate angles to check for rotations by, in degrees.  In the case of a tie in the shape difference, the earlier angle from this array will be returned.\n\n```\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.norm-Tuple{Vector{<:Number}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.norm","text":"norm(v)\n\nGet the euclidean norm of the vector v.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.normalized_cross_correlation-Union{Tuple{T}, Tuple{T, T}} where T<:AbstractArray","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.normalized_cross_correlation","text":"normalized_cross_corr(f1,f2)\n\nReturn the normalized cross-correlation between the psi-s curves p1 and p2.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.register-Tuple{Any, Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.register","text":"Finds the image rotation angle in test_angles which minimizes the shape difference between im_reference and im_target. The default test angles are shown in register_default_angles_rad. Use imrotate_function=imrotate_bin_<clockwise|counterclockwise>_<radians|degrees> to get angles <clockwise|counterclockwise> in <radians|degrees>.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.resample_boundary","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.resample_boundary","text":"resample_boundary(bd_points::Vector{<:CartesianIndex}, reduc_factor::Int64=2, bd::String=\"natural\")\n\nGet a uniform set of resampled boundary points from bd_points using cubic splines with specified boundary conditions\n\nThe resampled set of points is obtained using parametric interpolation of the points in bd_points. It is assumed that the separation between a pair of adjacent points is 1.\n\nArguments\n\nbd_points: Sequetial set of boundary points for the object of interest\nreduc_factor: Factor by which to reduce the number of points in bd_points (2 by default)\n\n-bd: Boundary condition, either 'natural' (default) or 'periodic'\n\nSee also bwtraceboundary\n\nExample\n\n```jldoctest; setup = :(using IceFloeTracker) julia> A = zeros(Int, 13, 16); A[2:6, 2:6] .= 1; A[4:8, 7:10] .= 1; A[10:12,13:15] .= 1; A[10:12,3:6] .= 1; julia> A 13×16 Matrix{Int64}:  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  0  0  0  0  0  0  1  1  1  0  0  0  1  1  1  1  0  0  0  0  0  0  1  1  1  0  0  0  1  1  1  1  0  0  0  0  0  0  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n\njulia> boundary = bwtraceboundary(A);\n\njulia> boundary[3] 9-element Vector{CartesianIndex}:  CartesianIndex(10, 13)  CartesianIndex(11, 13)  CartesianIndex(12, 13)  CartesianIndex(12, 14)  CartesianIndex(12, 15)  CartesianIndex(11, 15)  CartesianIndex(10, 15)  CartesianIndex(10, 14)  CartesianIndex(10, 13)\n\njulia> resample_boundary(boundary[3]) 4×2 Matrix{Float64}:  10.0     13.0  12.0357  13.5859  10.5859  15.0357  10.0     13.0\n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Tracking.shape_difference_rotation-Tuple{Any, Any, Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.shape_difference_rotation","text":"Computes the shape difference between imreference and imtarget for each angle in testangles. The reference image is held constant, while the target image is rotated. The testangles are interpreted as the angle of rotation from target to reference, so to find the best match, we rotate the reverse direction. A perfect match at angle A would imply imtarget is the same shape as if imreference was rotated by A.  Use imrotate_function=imrotate_bin_<clockwise|counterclockwise>_<radians|degrees> to get angles <clockwise|counterclockwise> in <radians|degrees>.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Preprocessing.LopezAcostaCloudMask-Tuple{AbstractArray{<:Union{ColorTypes.AbstractRGB, ColorTypes.Transparent3{C} where C<:ColorTypes.AbstractRGB, ColorTypes.TransparentRGB}}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Preprocessing.LopezAcostaCloudMask","text":"LopezAcostaCloudMask(prelim_threshold, band_7_threshold, band_2_threshold, ratio_lower, ratio_offset, ratio_upper)\n\nAbstractCloudMaskAlgorithm implementation of the cloud mask from Lopez-Acosta et al. 2019. Cloud masks algorithms are initialized with a set of parameters, then can be supplied to create_cloudmask as an argument. The Lopez-Acosta et al. cloudmask creates a piecewise linear bifurcation of band 2 and band 7 brightness in a MODIS 7-2-1 false color image using a sequence of thresholds on band 2 and band 7 and on the ratio of band 7 to band 2 brightness. \n\nExample:\n\nusing IceFloeTracker\nusing IceFloeTracker: Watkins2025GitHub\n\ndata_loader = Watkins2025GitHub(; ref=\"a451cd5e62a10309a9640fbbe6b32a236fcebc70\")\ncase = first(data_loader(c -> (c.case_number == 6 && c.satellite == \"terra\")))\ncm_algo = LopezAcostaCloudMask()\ncloud_mask = create_cloudmask(case.modis_falsecolor, cm_algo)\n\n# show image:\nGray.(cloud_mask)\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Preprocessing.Watkins2025CloudMask-Tuple{AbstractArray{<:Union{ColorTypes.AbstractRGB, ColorTypes.Transparent3{C} where C<:ColorTypes.AbstractRGB, ColorTypes.TransparentRGB}}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Preprocessing.Watkins2025CloudMask","text":"Watkins2025CloudMask(prelimthreshold, band7threshold, band2threshold, ratiolower, ratiooffset, ratioupper, markerstrel, openingstrel)\n\nExtension of the Lopez-Acosta et al. 2019 with parameters calibrated to the Ice Floe Validation Dataset. The Lopez-Acosta et al. cloudmask creates a piecewise linear bifurcation of band 2 and band 7 brightness  in a MODIS 7-2-1 false color image using a sequence of thresholds on band 2 and band 7 and on the ratio of band 7 to band 2 brightness. This extension first creates a cloud mask using the LopezAcostaCloudMask, then applies morphological operations to remove speckle and smooth boundaries.\n\nExample:\n\nusing IceFloeTracker\nusing IceFloeTracker: Watkins2025GitHub\n\ndata_loader = Watkins2025GitHub(; ref=\"a451cd5e62a10309a9640fbbe6b32a236fcebc70\")\ncase = first(data_loader(c -> (c.case_number == 6 && c.satellite == \"terra\")))\ncm_algo = Watkins2025CloudMask()\ncloud_mask = create_cloudmask(case.modis_falsecolor, cm_algo)\n\n# show image:\nGray.(cloud_mask)\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Preprocessing.apply_cloudmask-Tuple{AbstractArray{<:Union{ColorTypes.AbstractRGB, ColorTypes.Transparent3{C} where C<:ColorTypes.AbstractRGB, ColorTypes.TransparentRGB}}, AbstractArray{Bool}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Preprocessing.apply_cloudmask","text":"apply_cloudmask(false_color_image, cloudmask)\n\nZero out pixels containing clouds where clouds and ice are not discernable. Arguments should be of the same size.\n\nArguments\n\nimg: RGB, RGBA, or Gray image to be masked\ncloudmask: binary cloudmask with clouds = 1, else = 0\nmodify_channel_1: optional keyword argument for RGB images. If true, set the first channel to 0 in the returned image.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Preprocessing.apply_landmask-Tuple{AbstractMatrix, BitMatrix}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Preprocessing.apply_landmask","text":"apply_landmask(input_image, landmask_binary)\n\nZero out pixels in all channels of the input image using the binary landmask.\n\nArguments\n\ninput_image: truecolor RGB image\nlandmask_binary: binary landmask with 1=land, 0=water/ice\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Preprocessing.apply_landmask-Tuple{Any, Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Preprocessing.apply_landmask","text":"apply_landmask(img, landmask; as_indices::Bool=false)\n\nApply the landmask to the input image, optionally returning the indices of non-masked (ocean/ice) pixels.\n\nArguments\n\nimg: input image (e.g., ice mask or RGB image)\nlandmask: binary landmask (1=ocean/ice, 0=land)\nas_indices: if true, return indices of non-masked pixels; otherwise, return masked image\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Preprocessing.create_cloudmask","page":"IceFloeTracker.jl","title":"IceFloeTracker.Preprocessing.create_cloudmask","text":"create_cloudmask(img, f::AbstractCloudMaskAlgorithm)\n\nCloud masks in the IFT are BitMatrix objects such that for an image I and cloudmask C, cloudy pixels can be selected by I[C], and clear-sky pixels can be selected with I[.!C]. Construction of a cloud mask uses the syntax\n\nf = CloudMaskAlgorithm(parameters)\nC = create_cloudmask(img; CloudMaskAlgorithm)\n\nBy default, create_cloudmask uses the algorithm found in [1]. This algorithm converts a 3-channel MODIS 7-2-1 false color image into a 1-channel binary matrix in which clouds = 1 and anything else = 0. The algorithm aims to identify patches of opaque cloud while allowing thin and transparent cloud to remain. This algorithm is instantiated using\n\nf = LopezAcostaCloudMask()\n\nIn this case, the default values are applied. It can also called using a set of customized parameters. These values must be real numbers between 0 and 1. To reproduce the default parameters, you may call\n\nf = LopezAcostaCloudMask(prelim_threshold=110/255, band_7_threshold=200/255, band_2_threshold=190/255, ratio_lower=0.0, ratio_upper=0.75).\n\nA stricter cloud mask was defined in [2], covering more cloudy pixels while minimally impacting the masking of cloud-covered ice pixels.\n\nf = LopezAcostaCloudMask(prelim_threshold=53/255, band_7_threshold=130/255, band_2_threshold=169/255, ratio_lower=0.0, ratio_upper=0.53).\n\nThese parameters together define a piecewise linear partition of pixels based on their Band 7 and Band 2 callibrated reflectance. Pixels with intensity above prelim_threshold are considered as potential cloudy pixels. Then, pixels with Band 7 reflectance less than band_7_threshold, Band 2 reflectance greater than band_2_threshold, and Band 7 to Band 2 ratios between ratio_lower and ratio_upper are removed from the cloud mask (i.e., set to cloud-free).\n\nArguments\n\nfalse_color_image: corrected reflectance false color image - bands [7,2,1]\nprelim_threshold: threshold value used to identify clouds in band 7, N0f8(RGB intensity/255)\nband_7_threshold: threshold value used to identify cloud-ice in band 7, N0f8(RGB intensity/255)\nband_2_threshold: threshold value used to identify cloud-ice in band 2, N0f8(RGB intensity/255)\nratio_lower: threshold value used to set lower ratio of cloud-ice in bands 7 and 2\nratio_upper: threshold value used to set upper ratio of cloud-ice in bands 7 and 2\nratio_offset: offset value used to adjust the upper ratio of cloud-ice in bands 7 and 2\n\nLopez-Acosta, R., Schodlok, M. P., & Wilhelmus, M. M. (2019). Ice Floe Tracker: An algorithm to automatically retrieve Lagrangian trajectories via feature matching from moderate-resolution visual imagery. Remote Sensing of Environment, 234(111406), 1–15. (https://doi.org/10.1016/j.rse.2019.111406)[https://doi.org/10.1016/j.rse.2019.111406]\nWatkins, D.M., Kim, M., Paniagua, C., Divoll, T., Holland, J.G., Hatcher, S., Hutchings, J.K., and Wilhelmus, M.M. (in prep). Calibration and validation of the Ice Floe Tracker algorithm. \n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Preprocessing.create_landmask-Union{Tuple{T}, Tuple{T, AbstractMatrix{Bool}}} where T<:(AbstractMatrix)","page":"IceFloeTracker.jl","title":"IceFloeTracker.Preprocessing.create_landmask","text":"create_landmask(landmask_image, struct_elem, fill_value_lower, fill_value_upper)\n\nConvert a land mask image to a 1-channel binary matrix, and use a structuring element to extend a buffer to mask complex coastal features, and fill holes in the dilated image. In the resulting mask, land = 0 and ocean = 1. Returns a named tuple with the dilated and non-dilated landmask.\n\nArguments\n\nlandmask_image: RGB land mask image from fetchdata\nstruct_elem: structuring element for dilation (optional)\nfill_value_lower: fill holes having at least these many pixels (optional)\nfill_value_upper: fill holes having at most these many pixels (optional)\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Preprocessing.make_landmask_se","page":"IceFloeTracker.jl","title":"IceFloeTracker.Preprocessing.make_landmask_se","text":"make_landmask_se()\n\nCreate a structuring element for dilating the landmask.\n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Morphology.branch-Tuple{T} where T<:(AbstractArray{Bool})","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.branch","text":"branch(img::AbstractArray{Bool})\n\nFind branch points in skeletonized image img according to Definition 3 of [1].\n\n[1] Arcelli, Carlo, and Gabriella Sanniti di Baja. \"Skeletons of planar patterns.\" Machine Intelligence and Pattern Recognition. Vol. 19. North-Holland, 1996. 99-143.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Morphology.bridge-Tuple{T} where T<:(AbstractArray{Bool})","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.bridge","text":"bridge(bw)\n\nSet 0-valued pixels to 1 if they have two nonzero neighbors that are not connected. Note the following exceptions:\n\n0 0 0           0 0 0 1 0 1  becomes  1 1 1 0 0 0           0 0 0\n\n1 0 1           1 1 1 0 0 0  becomes  0 0 0 0 0 0           0 0 0\n\nThe same applies to all their corresponding rotations.\n\nExamples\n\njulia> bw = [0 0 0; 0 0 0; 1 0 1]\n3×3 Matrix{Int64}:\n 0  0  0\n 0  0  0\n 1  0  1\n\njulia> bridge(bw)\n3×3 BitMatrix:\n 0  0  0\n 0  0  0\n 1  1  1\n\njulia> bw = [1 0 0; 1 0 1; 0 0 1]\n3×3 Matrix{Int64}:\n 1  0  0\n 1  0  1\n 0  0  1\n\njulia> bridge(bw)\n3×3 BitMatrix:\n 1  1  0\n 1  1  1\n 0  1  1\n\n julia> bw = [1 0 1; 0 0 0; 1 0 1]\n3×3 Matrix{Int64}:\n 1  0  1\n 0  0  0\n 1  0  1\n\njulia> bridge(bw)\n3×3 BitMatrix:\n 1  1  1\n 1  1  1\n 1  1  1\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Morphology.bwareamaxfilt","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.bwareamaxfilt","text":"bwareamaxfilt(bwimg::AbstractArray{Bool}, conn)\n\nFilter the smaller (by area) connected components in bwimg keeping the (assumed unique) largest.\n\nUses 8-pixel connectivity by default (conn=8). Use conn=4 for 4-pixel connectivity.\n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Morphology.bwareamaxfilt!","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.bwareamaxfilt!","text":"bwareamaxfilt!(bwimg::AbstractArray)\n\nIn-place version of bwareamaxfilt.\n\nSee also bwareamaxfilt \n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Morphology.bwperim-Tuple{T} where T<:AbstractMatrix{Bool}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.bwperim","text":"bwperim(bwimg)\n\nLocate the pixels at the boundary of objects in an binary image bwimg using 8-pixel connectivity.\n\nArguments\n\nbwimg: Binary (black/white – 1/0) image\n\nExamples\n\njulia> A = zeros(Bool, 13, 16); A[2:6, 2:6] .= 1; A[4:8, 7:10] .= 1; A[10:12,13:15] .= 1; A[10:12,3:6] .= 1;\n\njulia> A\n13×16 Matrix{Bool}:\n 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n 0  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0\n 0  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0\n 0  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0\n 0  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0\n 0  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0\n 0  0  0  0  0  0  1  1  1  1  0  0  0  0  0  0\n 0  0  0  0  0  0  1  1  1  1  0  0  0  0  0  0\n 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n 0  0  1  1  1  1  0  0  0  0  0  0  1  1  1  0\n 0  0  1  1  1  1  0  0  0  0  0  0  1  1  1  0\n 0  0  1  1  1  1  0  0  0  0  0  0  1  1  1  0\n 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n\n julia> bwperim(A)\n13×16 Matrix{Bool}:\n 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n 0  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0\n 0  1  0  0  0  1  0  0  0  0  0  0  0  0  0  0\n 0  1  0  0  0  0  1  1  1  1  0  0  0  0  0  0\n 0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0\n 0  1  1  1  1  1  0  0  0  1  0  0  0  0  0  0\n 0  0  0  0  0  0  1  0  0  1  0  0  0  0  0  0\n 0  0  0  0  0  0  1  1  1  1  0  0  0  0  0  0\n 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n 0  0  1  1  1  1  0  0  0  0  0  0  1  1  1  0\n 0  0  1  0  0  1  0  0  0  0  0  0  1  0  1  0\n 0  0  1  1  1  1  0  0  0  0  0  0  1  1  1  0\n 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Morphology.filt_except_label-Tuple{Matrix{Int64}, Int64}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.filt_except_label","text":"filt_except_label(labeled_arr::Array{Int64, 2}, label::Int64)\n\nMake 0 all values in labeled_arr that are not equal to label.\n\nSee also filt_except_label! \n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Morphology.get_areas-Union{Tuple{Matrix{T}}, Tuple{T}} where T","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.get_areas","text":"get_areas(labeled_arr::Array{T, 2})::Dict{T, Int} where T\n\nGet the \"areas\" (count of pixels of a given label) of the connected components in labeled_arr.\n\nReturn a dictionary with the frequency distribution: label => countoflabel.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Morphology.get_max_label-Tuple{Dict{Int64, Int64}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.get_max_label","text":"get_max_label(d::Dict{Int, Int})\n\nGet the label k in dictionary d for which d[k] is maximal.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Morphology.hbreak!-Tuple{T} where T<:(AbstractArray{Bool})","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.hbreak!","text":"hbreak!(img::AbstractArray{Bool})\n\nInplace version of hbreak. See also hbreak.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Morphology.hbreak-Tuple{Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.hbreak","text":"hbreak(img::AbstractArray{Bool})\n\nRemove H-connected pixels in the binary image img. See also hbreak! for an inplace version of this function.\n\nExamples\n\n\njulia> h1 = trues(3,3); h1[[1 3], 2] .= false; h1     \n3×3 BitMatrix:    \n 1  0  1\n 1  1  1\n 1  0  1\n\njulia> h2 = trues(3,3); h2[2, [1 3]] .= false; h2     \n3×3 BitMatrix:    \n 1  1  1\n 0  1  0\n 1  1  1\n\njulia> hbreak!(h1); h1 # modify h1 inplace\n3×3 BitMatrix:\n 1  0  1\n 1  0  1\n 1  0  1\n\njulia> hbreak(h2) \n3×3 BitMatrix:\n 1  1  1\n 0  0  0\n 1  1  1\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Morphology.imextendedmin","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.imextendedmin","text":"imextendedmin(img)\n\nMimics MATLAB's imextendedmin function that computes the extended-minima transform, which is the regional minima of the H-minima transform. Regional minima are connected components of pixels with a constant intensity value. This function returns a transformed bitmatrix.\n\nArguments\n\nimg: image object\nh: suppress minima below this depth threshold\nconn: neighborhood connectivity; in 2D 1 = 4-neighborhood and 2 = 8-neighborhood\n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Morphology.impose_minima-Union{Tuple{T}, Tuple{AbstractArray{T}, AbstractArray{Bool}}} where T<:Integer","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.impose_minima","text":"impose_minima(I::AbstractArray{T}, BW::AbstractArray{Bool}) where {T<:Integer}\n\nUse morphological reconstruction to enforce minima on the input image I at the positions where the binary mask BW is non-zero.\n\nIt supports both integer and grayscale images using different implementations for each.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Morphology.imregionalmin","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.imregionalmin","text":"imregionalmin(img, conn=2)\n\nCompute the regional minima of the image img using the connectivity conn.\n\nReturns a bitmatrix of the same size as img with the regional minima.\n\nArguments\n\nimg: Image object\nconn: Neighborhood connectivity; in 2D, 1 = 4-neighborhood and 2 = 8-neighborhood\n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Morphology.make_hbreak_dict-Tuple{}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.make_hbreak_dict","text":"make_hbreak_dict()\n\nBuild dict with the two versions of an H-connected 3x3 neighboorhood.\n\nh1 =   [1 0 1              1 1 1              1 0 1]    \n\nh2 =   [1 1 1              0 1 0              1 1 1]  \n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Morphology.morph_fill-Tuple{T} where T<:(AbstractArray{Bool})","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.morph_fill","text":"morph_fill(bw::T)::T where {T<:AbstractArray{Bool}}\n\nFill holes in binary image bw by setting 0-valued pixels to 1 if they are surrounded by 1-valued pixels.\n\nExamples\n\njulia> bw = Bool[\n        0 0 0 0 0\n        0 1 1 1 0\n        0 1 0 1 0\n        0 1 1 1 0\n        0 0 0 0 0\n    ];\n\njulia> morph_fill(bw)\n5×5 Matrix{Bool}:\n 0  0  0  0  0\n 0  1  1  1  0\n 0  1  1  1  0\n 0  1  1  1  0\n 0  0  0  0  0\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Morphology.reconstruct","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.reconstruct","text":"reconstruct(img, se, type, invert)\n\nPerform closing/opening by reconstruction on img.\n\nArguments\n\nimg::AbstractArray: The input image.\nse::AbstractArray: The structuring element.\ntype::String: The type of morphological operation to perform. Must be either \"dilation\" (close by reconstruction) or \"erosion\" (open by reconstruction).\ninvert::Bool=true: Invert marker and mask before reconstruction.\n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Filtering.conditional_histeq-Tuple{Any, Any, Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Filtering.conditional_histeq","text":"conditional_histeq(\n    image,\n    clouds_red,\n    tiles;\n    entropy_threshold::Real=4.0,\n    white_threshold::Real=25.5,\n    white_fraction_threshold::Real=0.4,\n)\n\nPerforms conditional histogram equalization on a true color image.\n\nArguments\n\nimage: The true color image to be equalized.\nclouds_red: The land/cloud masked red channel of the false color image.\ntiles: the output from get_tiles(image) specifying the tiling to use on the image.\nentropy_threshold: The entropy threshold used to determine if a block should be equalized. Default is 4.0.\nwhite_threshold: The white threshold used to determine if a pixel should be considered white. Default is 25.5.\nwhite_fraction_threshold: The white fraction threshold used to determine if a block should be equalized. Default is 0.4.\n\nReturns\n\nThe equalized true color image.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Filtering.histeq-Tuple{S} where S<:(AbstractArray{<:Integer})","page":"IceFloeTracker.jl","title":"IceFloeTracker.Filtering.histeq","text":"histeq(img)\nhisteq(img; nbins=64)\n\nHistogram equalization of img using nbins bins.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Filtering.imadjust-Union{Tuple{AbstractArray{<:Integer}}, Tuple{T}} where T<:AbstractFloat","page":"IceFloeTracker.jl","title":"IceFloeTracker.Filtering.imadjust","text":"imadjust(img; low, high)\n\nAdjust the contrast of an image using linear stretching. The image is normalized to [0, 1] and then stretched to the range [low, high].\n\nArguments\n\nimg: The input image.\nlow: The lower bound of the stretched image. Default is 0.01.\nhigh: The upper bound of the stretched image. Default is 0.99.\n\nReturns\n\nThe contrast-adjusted image in the range [0, 255].\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Filtering.imgradientmag-Tuple{Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Filtering.imgradientmag","text":"imgradientmag(img)\n\nCompute the gradient magnitude of an image using the Sobel operator.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Filtering.nonlinear_diffusion-Tuple{AbstractArray{<:Union{ColorTypes.AbstractRGB, ColorTypes.AbstractGray, ColorTypes.Transparent3{C} where C<:ColorTypes.AbstractRGB, ColorTypes.TransparentRGB}}, Float64, Number, Int64}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Filtering.nonlinear_diffusion","text":"Perform nonlinear diffusion on an input image. By default, use the Perona-Malik method.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Filtering.rgb2gray-Tuple{Array{Float64, 3}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Filtering.rgb2gray","text":"rgb2gray(rgbchannels::Array{Float64, 3})\n\nConvert an array of RGB channel data to grayscale in the range [0, 255].\n\nIdentical to MATLAB rgb2gray (https://www.mathworks.com/help/matlab/ref/rgb2gray.html).\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Filtering.rgb2gray-Tuple{Matrix{ColorTypes.RGB{Float64}}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Filtering.rgb2gray","text":"rgb2gray(img::Matrix{RGB{Float64}})\n\nConvert an RGB image to grayscale in the range [0, 255].\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Filtering.unsharp_mask","page":"IceFloeTracker.jl","title":"IceFloeTracker.Filtering.unsharp_mask","text":"unsharp_mask(img, radius, amount, threshold)\n\nEnhance image sharpness by weighted differencing of the image and a Gaussian blurred image.\nIf ``B`` is the blurred version of image ``I``, then an unsharp mask sharpened image is obtained by\n``S = I + (I - B)*A``\nThe amount of sharpening is determined by the factor A. An option threshold can be supplied such\nthat the sharpening is only applied where ``I - B`` is greater than some factor.\n\n# Arguments\nimg: input image\nradius: standard deviation of the Gaussian blur\namount: multiplicative factor\nthreshold: minimum difference for applying the sharpening\n\n# Returns\nSharpened image\n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Filtering.unsharp_mask-Tuple{Matrix{Int64}, Any, Any, Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Filtering.unsharp_mask","text":"unsharp_mask(image_gray, smoothing_param, intensity, clampmax)\n\nApply unsharp masking on (equalized) grayscale ([0, clampmax]) image to enhance its sharpness.\n\nArguments\n\nimage_gray: The input grayscale image, typically already equalized.\nsmoothing_param::Int: The pixel radius for Gaussian blurring (typically between 1 and 10).\nintensity: The amount of sharpening to apply. Higher values result in more pronounced sharpening.\nclampmax: upper limit of intensity values in the returned image.`\n\nReturns\n\nThe sharpened grayscale image with values clipped between 0 and clapmax.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Data","page":"IceFloeTracker.jl","title":"IceFloeTracker.Data","text":"Module for loading validated ice floe data.\n\n\n\n\n\n","category":"module"},{"location":"#IceFloeTracker.Data.ValidationDataLoader","page":"IceFloeTracker.jl","title":"IceFloeTracker.Data.ValidationDataLoader","text":"Loader for validated ice floe data.\n\n\n\n\n\n","category":"type"},{"location":"#IceFloeTracker.Data.Watkins2025GitHub","page":"IceFloeTracker.jl","title":"IceFloeTracker.Data.Watkins2025GitHub","text":"Watkins2025GitHub(; ref)()\nWatkins2025GitHub(; ref, [url, dataset_metadata_path, cache_dir])(; [case_filter])\n\nLoader for validated ice floe data from the Watkins 2025 Ice Floe Validation Dataset.\n\nThe loader is initialized with a specific git ref (tag or commit ID) from which to load the data.\n\njulia> data_loader = Watkins2025GitHub(; ref=\"a451cd5e62a10309a9640fbbe6b32a236fcebc70\")\n\nWatkins2025GitHub fields: \n\nref (optional): git permalink of the commit from which to load the data\ncache_dir (optional): local path where the data will be stored, which defaults to /tmp/Watkins2025/.\nurl (optional): URL of the GitHub repository with the dataset\ndataset_metadata_path (optional): path within the repository to a CSV file describing the data\n\nThe loader is then called with an optional case_filter function to filter which cases to load. This checks each case's metadata, and if the function returns true, the case is included in the returned dataset.\n\njulia> dataset = data_loader(;case_filter=c -> (\n                        c.visible_floes == \"yes\" &&\n                        c.cloud_category_manual == \"none\" &&\n                        c.artifacts == \"no\"\n                    ));\n\nThe returned dataset (a ValidationDataSet) has a metadata field with a DataFrame of the cases which passed the filter:\n\njulia> dataset.metadata\n8×28 DataFrame\n    Row │ case_number  region        start_date  center_lon  center_lat  center_x  center_y  month  sea_ice_fr ⋯\n        │ Int64        String31      Date        Float64     Float64     Int64     Int64     Int64  Float64    ⋯\n   ─────┼───────────────────────────────────────────────────────────────────────────────────────────────────────\n      1 │          11  baffin_bay    2011-07-02    -70.7347     72.3303   -837500  -1737500      7             ⋯\n      2 │          14  baffin_bay    2022-07-06    -69.0755     72.3157   -787500  -1762500      7\n      3 │          48  beaufort_sea  2021-04-27   -140.612      70.1346  -2162500    212500      4\n      4 │          48  beaufort_sea  2021-04-27   -140.612      70.1346  -2162500    212500      4\n      5 │          54  beaufort_sea  2015-05-16   -136.675      70.4441  -2137500     62500      5             ⋯\n      6 │          54  beaufort_sea  2015-05-16   -136.675      70.4441  -2137500     62500      5\n      7 │         128  hudson_bay    2019-04-15    -91.9847     57.853   -2612500  -2437500      4\n      8 │         166  laptev_sea    2016-09-04    136.931      79.7507    -37500   1112500      9\n                                                                                        20 columns omitted\n\nThe dataset contains ValidationDataCase objects. Each ValidationDataCase has metadata fields including:\n\nname: name of the case\nmetadata: dictionary of metadata for the case, corresponding to a row in the dataset.metadata DataFrame\n\nEach ValidationDataCase also has data fields including:\n\nmodis_truecolor: MODIS true color image\nmodis_falsecolor: MODIS false color image\nmodis_landmask: MODIS landmask image\nmodis_cloudfraction: MODIS cloud fraction image\nmasie_landmask: MASIE landmask image\nmasie_seaice: MASIE sea ice image\n\nA ValidationDataCase may have validated data fields including:\n\nvalidated_binary_floes: binary image of validated floes\nvalidated_labeled_floes: labeled image of validated floes\nvalidated_floe_properties: CSV file of validated floe properties\n\nThe dataset can be iterated over to get each ValidationDataCase: Example:\n\njulia> for case in dataset\n           println(case.name * \n                   \": sea ice fraction: \" * string(case.metadata[:sea_ice_fraction]) *\n                   \", true color image size: \" * string(size(case.modis_truecolor)))\n       end\n011-baffin_bay-100km-20110702-aqua-250m: sea ice fraction: 0.8, true color image size: (400, 400)\n014-baffin_bay-100km-20220706-terra-250m: sea ice fraction: 1.0, true color image size: (400, 400)\n048-beaufort_sea-100km-20210427-aqua-250m: sea ice fraction: 1.0, true color image size: (400, 400)\n048-beaufort_sea-100km-20210427-terra-250m: sea ice fraction: 1.0, true color image size: (400, 400)\n054-beaufort_sea-100km-20150516-aqua-250m: sea ice fraction: 1.0, true color image size: (400, 400)\n054-beaufort_sea-100km-20150516-terra-250m: sea ice fraction: 1.0, true color image size: (400, 400)\n128-hudson_bay-100km-20190415-aqua-250m: sea ice fraction: 1.0, true color image size: (400, 400)\n166-laptev_sea-100km-20160904-aqua-250m: sea ice fraction: 1.0, true color image size: (400, 400)\n\ninfo: `dataset` and `dataset.data`\nIterating over the dataset is the same as iterating over dataset.data,  so you could also write for case in dataset.data....)\n\nTo get the first case in the dataset, you can use first(...):\n\njulia> first(dataset)\nValidationDataCase(\"011-baffin_bay-100km-20110702-aqua-250m\", Dict{Symbol, Any}(:sea_ice_fraction => 0.8, :vi...\n\njulia> first(dataset).validated_labeled_floes\nSegmented Image with:\nlabels map: 400×400 Matrix{Int64}\nnumber of labels: 105\n\njulia> first(dataset).modis_truecolor\n400×400 Array{RGBA{N0f8},2} with eltype ColorTypes.RGBA{FixedPointNumbers.N0f8}:\n RGBA{N0f8}(0.094,0.133,0.169,1.0)  RGBA{N0f8}(0.051,0.094,0.118,1.0) ...\n\n\ntip: Cacheing\nData are downloaded to the <cache_dir>/<ref>, e.g. /tmp/Watkins2025/a451cd5e62a10309a9640fbbe6b32a236fcebc70/.  If a file of the correct name already exists in that path, if loaded again the cached data will be returned.There are no checks to ensure that the cached data are up-to-date,  so if the data change in the source for that ref, the loader won't load the new data. In this case, you can clear the cache by deleting the cache directory,  e.g. rm -r /tmp/Watkins2025/a451cd5e62a10309a9640fbbe6b32a236fcebc70/.\n\n```\n\n\n\n\n\n","category":"type"},{"location":"#IceFloeTracker.Geospatial.latlon-Tuple{AbstractString}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Geospatial.latlon","text":"latlon(imgpath::AbstractString)\n\nReads the GeoTiff located at <imgpath>, extracts the coordinate reference system, and produces a lookup table with for the column and row values in the same projection as the GeoTiff and a 2D array for latitude and longitude.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.ImageUtils","page":"IceFloeTracker.jl","title":"IceFloeTracker.ImageUtils","text":"Module for general image utilities.\n\n\n\n\n\n","category":"module"},{"location":"#IceFloeTracker.ImageUtils.bump_tile-Union{Tuple{S}, Tuple{Tuple{UnitRange{S}, UnitRange{S}}, Tuple{S, S}}} where S<:Int64","page":"IceFloeTracker.jl","title":"IceFloeTracker.ImageUtils.bump_tile","text":"bump_tile(tile::Tuple{UnitRange{Int64}, UnitRange{Int64}}, dims::Tuple{Int,Int})::Tuple{UnitRange{Int}, UnitRange{Int}}\n\nAdjust the tile dimensions by adding extra rows and columns.\n\nArguments\n\ntile::Tuple{Int,Int,Int,Int}: A tuple representing the tile dimensions (a, b, c, d).\ndims::Tuple{Int,Int}: A tuple representing the extra rows and columns to add (extrarows, extracols).\n\nReturns\n\nTuple{UnitRange{Int}, UnitRange{Int}}: A tuple of ranges representing the new tile dimensions.\n\nExamples\n\n```julia julia> bump_tile((1:3, 1:4), (1, 1)) (1:4, 1:5)\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.ImageUtils.get_area_missed-Tuple{Int64, Tuple{Int64, Int64}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.ImageUtils.get_area_missed","text":"get_area_missed(side_length::Int, dims::Tuple{Int,Int})::Float64\n\nCalculate the proportion of the area that is not covered by tiles of a given side length.\n\nArguments\n\nside_length::Int: The side length of the tile.\ndims::Tuple{Int,Int}: A tuple representing the dimensions (width, height).\n\nReturns\n\nFloat64: The proportion of the area that is not covered by the tiles.\n\nExamples\n\n``` julia> getareamissed(5, (10, 20)) 0.0\n\njulia> getareamissed(7, (10, 20)) 0.51\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.ImageUtils.get_brighten_mask-Tuple{Any, Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.ImageUtils.get_brighten_mask","text":"get_brighten_mask(equalized_gray_reconstructed_img, gamma_green)\n\nArguments\n\nequalized_gray_reconstructed_img: The equalized gray reconstructed image (uint8 in Matlab).\ngamma_green: The gamma value for the green channel (also uint8).\n\nReturns\n\nDifference equalizedgrayreconstructedimg - gammagreen clamped between 0 and 255.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.ImageUtils.get_optimal_tile_size-Tuple{Int64, Tuple{Int64, Int64}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.ImageUtils.get_optimal_tile_size","text":"get_optimal_tile_size(l0::Int, dims::Tuple{Int,Int}) -> Int\n\nCalculate the optimal tile size in the range [l0-1, l0+1] for the given size l0 and image dimensions dims.\n\nDescription\n\nThis function computes the optimal tile size for tiling an area with given dimensions. It ensures that the initial tile size l0 is at least 2 and not larger than any of the given dimensions. The function evaluates candidate tile sizes and selects the one that minimizes the area missed by its corresponding tiling. In case of a tie, it prefers the larger tile size.\n\nExample\n\njulia> get_optimal_tile_size(3, (10, 7))\n2\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.ImageUtils.get_tile_dims-Tuple{Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.ImageUtils.get_tile_dims","text":"get_tile_dims(tile)\n\nCalculate the dimensions of a tile.\n\nArguments\n\ntile::Tuple{UnitRange{Int},UnitRange{Int}}: A tuple representing the tile dimensions.\n\nReturns\n\nTuple{Int,Int}: A tuple representing the width and height of the tile.\n\nExamples\n\n```julia julia> gettiledims((1:3, 1:4)) (4, 3)\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.ImageUtils.get_tile_meta-Tuple{Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.ImageUtils.get_tile_meta","text":"get_tile_meta(tile)\n\nExtracts metadata from a given tile.\n\nArguments\n\ntile: A collection of tuples, where each tuple represents a coordinate pair.\n\nReturns\n\nA tuple (a, b, c, d) where:\na: The first element of the first tuple in tile.\nb: The last element of the first tuple in tile.\nc: The first element of the last tuple in tile.\nd: The last element of the last tuple in tile.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.ImageUtils.get_tiles-Tuple{Any, Int64}","page":"IceFloeTracker.jl","title":"IceFloeTracker.ImageUtils.get_tiles","text":"get_tiles(array, side_length)\n\nGenerate a collection of tiles from an array.\n\nUnlike TileIterator, the function adjusts the bottom and right edges of the tile matrix if they are smaller than half the tile size side_length.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.ImageUtils.get_tiles-Union{Tuple{T}, Tuple{Any, Tuple{T, T}}} where T<:Int64","page":"IceFloeTracker.jl","title":"IceFloeTracker.ImageUtils.get_tiles","text":"get_tiles(array, t::Tuple{Int,Int})\n\nGenerate a collection of tiles from an array.\n\nThe function adjusts the bottom and right edges of the tile matrix if they are smaller than half the tile sizes in t.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.ImageUtils.imbrighten-Tuple{Any, Any, Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.ImageUtils.imbrighten","text":"imbrighten(img, brighten_mask, bright_factor)\n\nBrighten the image using a mask and a brightening factor.\n\nArguments\n\nimg: The input image.\nbrighten_mask: A mask indicating the pixels to brighten.\nbright_factor: The factor by which to brighten the pixels.\n\nReturns\n\nThe brightened image.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.ImageUtils.masker-Tuple{AbstractArray}","page":"IceFloeTracker.jl","title":"IceFloeTracker.ImageUtils.masker","text":"masker(mask::AbstractArray, img::AbstractArray{<:Colorant})\nmasker(mask::AbstractArray)\n\nReturns a version of img with masked pixels made transparent. If img has an alpha channel, it is combined with the mask.\n\nmasker(mask) returns a function which can be used to apply the mask.\n\nExamples\n\nWith a BitMatrix type of mask, truthy values in the mask are transparent in the output.\n\njulia> using Images\n\njulia> hide = true;\n\njulia> pass = false;\n\njulia> bit_mask = [hide hide pass; pass pass hide]\n2×3 Matrix{Bool}:\n 1  1  0\n 0  0  1\n\n julia> img = parse.(Colorant, [\"red\" \"green\" \"blue\"; \"cyan\" \"magenta\" \"yellow\"])\n2×3 Array{RGB{N0f8},2} with eltype RGB{N0f8}:\n RGB{N0f8}(1.0,0.0,0.0)  RGB{N0f8}(0.0,0.502,0.0)  RGB{N0f8}(0.0,0.0,1.0)\n RGB{N0f8}(0.0,1.0,1.0)  RGB{N0f8}(1.0,0.0,1.0)    RGB{N0f8}(1.0,1.0,0.0)\n\n julia> masker(bit_mask, img)\n2×3 Array{ARGB{N0f8},2} with eltype ARGB{N0f8}:\n ARGB{N0f8}(1.0,0.0,0.0,0.0)  ARGB{N0f8}(0.0,0.502,0.0,0.0)  ARGB{N0f8}(0.0,0.0,1.0,1.0)\n ARGB{N0f8}(0.0,1.0,1.0,1.0)  ARGB{N0f8}(1.0,0.0,1.0,1.0)    ARGB{N0f8}(1.0,1.0,0.0,0.0)\n\nUsing the masker in a pipeline is also possible:\n\njulia> img |> masker(bit_mask)\n2×3 Array{ARGB{N0f8},2} with eltype ARGB{N0f8}:\n ARGB{N0f8}(1.0,0.0,0.0,0.0)  ARGB{N0f8}(0.0,0.502,0.0,0.0)  ARGB{N0f8}(0.0,0.0,1.0,1.0)\n ARGB{N0f8}(0.0,1.0,1.0,1.0)  ARGB{N0f8}(1.0,0.0,1.0,1.0)    ARGB{N0f8}(1.0,1.0,0.0,0.0)\n\nWhere the mask is itself an image with transparency,  areas which are opaque in the mask are transparent in the output. This corresopnds to overlaying the mask over the image, and hiding in the output those areas which were masked.\n\njulia> hide = AGray(0.5, 1);\n\njulia> pass = AGray(1, 0);\n\njulia> agray_mask = [hide hide pass; pass pass hide];\n\njulia> masker(agray_mask, img)\n2×3 Array{ARGB{N0f8},2} with eltype ARGB{N0f8}:\n ARGB{N0f8}(1.0,0.0,0.0,0.0)  ARGB{N0f8}(0.0,0.502,0.0,0.0)  ARGB{N0f8}(0.0,0.0,1.0,1.0)\n ARGB{N0f8}(0.0,1.0,1.0,1.0)  ARGB{N0f8}(1.0,0.0,1.0,1.0)    ARGB{N0f8}(1.0,1.0,0.0,0.0)\n\nAny pixels which are partially opaque in the mask, will be partially obscured in the output:\n\njulia> part = AGray(0.75, 0.5)\nAGray{Float64}(0.75,0.5)\n\njulia> partial_mask = [hide part pass; pass part hide]\n2×3 Array{AGray{Float64},2} with eltype AGray{Float64}:\n AGray{Float64}(0.5,1.0)  AGray{Float64}(0.75,0.5)  AGray{Float64}(1.0,0.0)\n AGray{Float64}(1.0,0.0)  AGray{Float64}(0.75,0.5)  AGray{Float64}(0.5,1.0)\n\njulia> masker(partial_mask, img)\n2×3 Array{ARGB{N0f8},2} with eltype ARGB{N0f8}:\n ARGB{N0f8}(1.0,0.0,0.0,0.0)  ARGB{N0f8}(0.0,0.502,0.0,0.502)  ARGB{N0f8}(0.0,0.0,1.0,1.0)\n ARGB{N0f8}(0.0,1.0,1.0,1.0)  ARGB{N0f8}(1.0,0.0,1.0,0.502)    ARGB{N0f8}(1.0,1.0,0.0,0.0)\n\nIf the image already has transparency,  this is combined with the mask.\n\njulia> imga = RGBA.(parse.(Colorant, [\"red\" \"transparent\" \"blue\"; \"cyan\" \"transparent\" \"yellow\"]))\n\n2×3 Array{RGBA{N0f8},2} with eltype RGBA{N0f8}:\n RGBA{N0f8}(1.0,0.0,0.0,1.0)  RGBA{N0f8}(0.0,0.0,0.0,0.0)  RGBA{N0f8}(0.0,0.0,1.0,1.0)\n RGBA{N0f8}(0.0,1.0,1.0,1.0)  RGBA{N0f8}(0.0,0.0,0.0,0.0)  RGBA{N0f8}(1.0,1.0,0.0,1.0)\n\njulia> masker(agray_mask, imga)\n2×3 Array{ARGB{N0f8},2} with eltype ARGB{N0f8}:\n ARGB{N0f8}(1.0,0.0,0.0,0.0)  ARGB{N0f8}(0.0,0.0,0.0,0.0)  ARGB{N0f8}(0.0,0.0,1.0,1.0)\n ARGB{N0f8}(0.0,1.0,1.0,1.0)  ARGB{N0f8}(0.0,0.0,0.0,0.0)  ARGB{N0f8}(1.0,1.0,0.0,0.0)\n\nWhere the mask is an image without transparency,  any non-zero pixels are masked:\n\njulia> gray_mask = Gray.([0.5 0.1 0.0; 0.0 0.0 1.0])\n2×3 Array{Gray{Float64},2} with eltype Gray{Float64}:\n\n Gray{Float64}(0.5)  Gray{Float64}(0.1)  Gray{Float64}(0.0)\n Gray{Float64}(0.0)  Gray{Float64}(0.0)  Gray{Float64}(1.0)\n\njulia> masker(gray_mask, img)\n2×3 Array{ARGB{N0f8},2} with eltype ARGB{N0f8}:\n ARGB{N0f8}(1.0,0.0,0.0,0.0)  ARGB{N0f8}(0.0,0.502,0.0,0.0)  ARGB{N0f8}(0.0,0.0,1.0,1.0)\n ARGB{N0f8}(0.0,1.0,1.0,1.0)  ARGB{N0f8}(1.0,0.0,1.0,1.0)    ARGB{N0f8}(1.0,1.0,0.0,0.0)\n\njulia> rgb_mask = parse.(Colorant, [\"red\" \"red\" \"black\"; \"black\" \"purple\" \"green\"])\n2×3 Array{RGB{N0f8},2} with eltype RGB{N0f8}:\n RGB{N0f8}(1.0,0.0,0.0)  RGB{N0f8}(1.0,0.0,0.0)      RGB{N0f8}(0.0,0.0,0.0)\n RGB{N0f8}(0.0,0.0,0.0)  RGB{N0f8}(0.502,0.0,0.502)  RGB{N0f8}(0.0,0.502,0.0)\n\njulia> masker(rgb_mask, img)\n2×3 Array{ARGB{N0f8},2} with eltype ARGB{N0f8}:\n ARGB{N0f8}(1.0,0.0,0.0,0.0)  ARGB{N0f8}(0.0,0.502,0.0,0.0)  ARGB{N0f8}(0.0,0.0,1.0,1.0)\n ARGB{N0f8}(0.0,1.0,1.0,1.0)  ARGB{N0f8}(1.0,0.0,1.0,0.0)    ARGB{N0f8}(1.0,1.0,0.0,0.0)\n\n\nWhere the mask is an array of Real numbers, 0-pixels will be completely unmasked, 1-pixels completely masked, and values between partially masked:\n\njulia> real_mask = [1.0 0.5 0.1; 0.1 0.2 1.0]\n\n2×3 Matrix{Float64}:\n 1.0  0.5  0.1\n 0.1  0.2  1.0\n\njulia> masker(real_mask, img)\n2×3 Array{ARGB{N0f8},2} with eltype ARGB{N0f8}:\n ARGB{N0f8}(1.0,0.0,0.0,0.0)    ARGB{N0f8}(0.0,0.502,0.0,0.502)  ARGB{N0f8}(0.0,0.0,1.0,0.902)\n ARGB{N0f8}(0.0,1.0,1.0,0.902)  ARGB{N0f8}(1.0,0.0,1.0,0.8)      ARGB{N0f8}(1.0,1.0,0.0,0.0)```\n\nWhere values are outside of the range [0, 1], \nthey are clamped to whichever of 0 and 1 is nearer:\n\njulia-repl julia> outofrange_mask = [5 2 0.75; -1 -2 1] 2×3 Matrix{Float64}:   5.0   2.0  0.75  -1.0  -2.0  1.0\n\njulia> masker(outofrange_mask, img) 2×3 Array{ARGB{N0f8},2} with eltype ARGB{N0f8}:  ARGB{N0f8}(1.0,0.0,0.0,0.0)  ARGB{N0f8}(0.0,0.502,0.0,0.0)  ARGB{N0f8}(0.0,0.0,1.0,0.251)  ARGB{N0f8}(0.0,1.0,1.0,1.0)  ARGB{N0f8}(1.0,0.0,1.0,1.0)    ARGB{N0f8}(1.0,1.0,0.0,0.0)```\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Utils.callable_store-Tuple{}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Utils.callable_store","text":"callable_store()\n\nCreate a store and a callback function to add key-value pairs to the store.\n\nReturns a store::Dict and a callback::Function which stores any kwargs passed to it in the store.\n\nExamples\n\nBasic usage is to store values using the callback function\n\njulia> store, callback = callable_store()\njulia> store\nDict{Any, Any}()\n\njulia> callback(;foo=\"bar\")  # echoes the updated store\nDict{Any, Any} with 1 entry:\n  :foo => \"bar\"\n\njulia> store  # values are available from the store object\nDict{Any, Any} with 1 entry:\n  :foo => \"bar\"\n\nA real-world use case is to extract data from a segmentation algorithm run:\n\njulia> intermediate_results, intermediate_results_callback = callable_store()\njulia> data = first(Watkins2025GitHub(; ref=\"a451cd5e62a10309a9640fbbe6b32a236fcebc70\")());\njulia> segments = LopezAcosta2019Tiling.Segment()(\n    data.modis_truecolor,\n    data.modis_falsecolor,\n    data.modis_landmask;\n    intermediate_results_callback,\n)\nSegmented Image with:\n  labels map: 400×400 Matrix{Int64}\n  number of labels: 12\n\njulia> intermediate_data\nDict{Any, Any} with 16 entries:\n  :binarized_tiling                       => Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0]\n  :icemask                                => Bool[1 1 … 1 1; 1 1 … 1 1; … ; 0 0 … 1 1; 0 0 … 1 1]\n  :equalized_gray                         => [0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0]\n  :morphed_residue                        => [0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0]\n  :L0mask                                 => Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0]\n  :segmented                              => Segmented Image with:…\n  :prelim_icemask2                        => [255 255 … 255 255; 255 255 … 255 255; … ; 255 255 … 255 255; 255 255 … 255 255]\n  :equalized_gray_sharpened_reconstructed => [0 0 … 0 0; 0 0 … 0 0; … ; 255 255 … 255 255; 255 255 … 255 255]\n  :gammagreen                             => [190.35 190.23 … 182.93 185.03; 191.68 190.6 … 185.04 192.08; … ; 163.87 173.33 … 108.02 108.18; 166.14 173.3 … 112.35 112.32]\n  :segment_mask                           => Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0]\n  :ref_img_cloudmasked                    => RGB{N0f8}[RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.008,0.706,0.761) RGB{N0f8}(0.0,0.722,0.769); RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.039,0.702,0.784) RGB{N0f8}(0.075,0.784,0.859); … ; RGB{…\n  :prelim_icemask                         => Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0]\n  :equalized_gray_reconstructed           => [0 0 … 0 0; 0 0 … 0 0; … ; 255 255 … 255 255; 255 255 … 255 255]\n  :final                                  => Bool[0 0 … 0 0; 0 1 … 1 0; … ; 0 0 … 1 0; 0 0 … 0 0]\n  :local_maxima_mask                      => [255 255 … 255 255; 255 255 … 255 255; … ; 255 255 … 255 255; 255 255 … 255 255]\n  :labeled                                => [0 0 … 0 0; 0 1 … 1 0; … ; 0 0 … 9 0; 0 0 … 0 0]\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Utils.@persist","page":"IceFloeTracker.jl","title":"IceFloeTracker.Utils.@persist","text":"@persist img fname\n@persist(img,fname)\n@persist img\n@persist(img)\n@persist img fname ts\n@persist(img, fname, ts)\n\nGiven a reference to an image object img, the macro persists (saves to a file) img to the current working directory using fname as filename. Returns img.\n\nArguments\n\nimg: Symbol expression representing an image object loaded in memory.\nfname: Optional filename for the persisted image.\nts: Optional boolean to attach timestamp to fname.\n\n\n\n\n\n","category":"macro"}]
}
