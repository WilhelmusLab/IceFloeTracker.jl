var documenterSearchIndex = {"docs":
[{"location":"tracking/#Tracking","page":"Tracking","title":"Tracking","text":"","category":"section"},{"location":"tracking/","page":"Tracking","title":"Tracking","text":"Ice floe tracking links objects in images pairwise.","category":"page"},{"location":"segmentation/#Segmentation","page":"Segmentation","title":"Segmentation","text":"","category":"section"},{"location":"segmentation/","page":"Segmentation","title":"Segmentation","text":"The segmentation functions are intended for use on the preprocessed imagery.","category":"page"},{"location":"segmentation/#Ice/Water-Discrimination","page":"Segmentation","title":"Ice/Water Discrimination","text":"","category":"section"},{"location":"segmentation/#Feature-Identification","page":"Segmentation","title":"Feature Identification","text":"","category":"section"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"(Image: Open this notebook in Colab)","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/#Segmentation-Algorithm-Workflows","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"","category":"section"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"This notebook demonstrates IceFloeTracker.jl's segmentation algorithms  with very basic examples of their use.","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"\n# Setup environment\nusing Pkg\nPkg.add(;name=\"IceFloeTracker\", rev=\"807/merge\")\nPkg.add(\"Images\")\n","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"\n# Load packages\nusing IceFloeTracker: LopezAcosta2019, LopezAcosta2019Tiling, Watkins2025GitHub\nusing Images: erode, segment_mean, labels_map, SegmentedImage, RGB, mosaicview\n","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/#Load-the-images","page":"Segmentation Algorithm Workflows","title":"Load the images","text":"","category":"section"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"Load the dataset from https://github.com/danielmwatkins/icefloevalidation_dataset using the Watkins2025GitHub data loader.","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"\ndata_loader = Watkins2025GitHub(; ref=\"a451cd5e62a10309a9640fbbe6b32a236fcebc70\")\n","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"The available data are listed in the metadata field:","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"\nfirst(data_loader().metadata, 10)\n","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"For the example, we choose a single case from Baffin Bay in May 2022.","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"\ndataset = data_loader(c-> c.case_number == 6 && c.satellite == \"terra\")\ncase = first(dataset)\n","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"The data include the true-color image:","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"\ntruecolor = RGB.(case.modis_truecolor) # TODO: remove RGB cast\n","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"... a false-color image:","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"\nfalsecolor = RGB.(case.modis_falsecolor) # TODO: remove RGB cast\n","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"... and a landmask, which in this particular case is empty:","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"\nlandmask = RGB.(case.modis_landmask) # TODO: remove RGB cast\n","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/#Run-the-segmentation-algorithm","page":"Segmentation Algorithm Workflows","title":"Run the segmentation algorithm","text":"","category":"section"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"The segmentation algorithm is an object with parameters as follows:","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"\nsegmentation_algorithm = LopezAcosta2019.Segment()\n","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"If we wanted to modify the options, we could include those in the call above.  See the documentation for LopezAcosta2019.Segment for details. The default parameters are as follows:","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"\ndump(segmentation_algorithm)\n","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"Run the algorithm as follows:","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"\nsegments = segmentation_algorithm(truecolor, falsecolor, landmask)\n","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"To show the results with each segment marked using its mean color:","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"\nmap(i -> segment_mean(segments, i), labels_map(segments))\n","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"We can do the same with the falsecolor image:","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"\n# Get the labels_map\nsegments_falsecolor = SegmentedImage(falsecolor, labels_map(segments))\nmap(i -> segment_mean(segments_falsecolor, i), labels_map(segments_falsecolor))\n","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"Let's compare the segmented output to the manually validated labels:","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"\nman_labels = case.validated_binary_floes\noutlines = man_labels .- erode(man_labels)\nseg_vs = map(i -> segment_mean(segments, i), labels_map(segments))\nmosaicview(truecolor, seg_vs .* (1 .- Float64.(outlines)), nrow=1)\n","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/#Run-the-segmentation-algorithm-with-tiling","page":"Segmentation Algorithm Workflows","title":"Run the segmentation algorithm with tiling","text":"","category":"section"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"The \"tiling\" version of the algorithm is an object:","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"\nsegmentation_algorithm_with_tiling = LopezAcosta2019Tiling.Segment()\n","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"It has more configurable parameters.  For details, see the documentation of LopezAcosta2019Tiling.Segment. The default parameters are as follows:","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"\ndump(segmentation_algorithm_with_tiling)\n","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"\nsegments = segmentation_algorithm_with_tiling(truecolor, falsecolor, landmask)\n","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"To show the results with each segment marked using its mean color:","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"\nmap(i -> segment_mean(segments, i), labels_map(segments))\n","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"With the falsecolor image:","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"\n# Get the labels_map\nsegments_falsecolor = SegmentedImage(falsecolor, labels_map(segments))\nmap(i -> segment_mean(segments_falsecolor, i), labels_map(segments_falsecolor))\n","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"Let's compare the segmented output to the manually validated labels:","category":"page"},{"location":"tutorials/lopez-acosta-2019-workflow/","page":"Segmentation Algorithm Workflows","title":"Segmentation Algorithm Workflows","text":"\nman_labels = case.validated_binary_floes\noutlines = man_labels .- erode(man_labels)\nseg_vs = map(i -> segment_mean(segments, i), labels_map(segments))\nmosaicview(truecolor, seg_vs .* (1 .- Float64.(outlines)), nrow=1)\n","category":"page"},{"location":"preprocessing/#Preprocessing","page":"Preprocessing","title":"Preprocessing","text":"","category":"section"},{"location":"preprocessing/","page":"Preprocessing","title":"Preprocessing","text":"IFT operates on optical satellite imagery. The main functions are designed with \"true color\" and \"false color\" imagery in mind, and have thus far primarily been tested on imagery from the Moderate Resolution Imaging Spectroradiometer (MODIS) from the NASA Aqua and Terra satellites. The preprocessing routines mask land and cloud features, and aim to adjust and sharpen the remainder of the images to amplify the contrast along the edges of sea ice floes. The functions use three different images: a land mask, a true color image, and a false color image. Examples are based on the NASA MODIS dataset.","category":"page"},{"location":"preprocessing/#Land-masks","page":"Preprocessing","title":"Land masks","text":"","category":"section"},{"location":"preprocessing/","page":"Preprocessing","title":"Preprocessing","text":"Landmask generation and dilation is handled by the function create_landmask. Landmask images from file are loaded as RGB matrices. This example uses an image from NASA EarthData landmask for Beaufort Sea.","category":"page"},{"location":"preprocessing/","page":"Preprocessing","title":"Preprocessing","text":"using IceFloeTracker\n\nrgb_landmask = IceFloeTracker.load(<landmask_path>);\nlandmask_imgs = IceFloeTracker.create_landmask(rgb_landmask);","category":"page"},{"location":"preprocessing/","page":"Preprocessing","title":"Preprocessing","text":"The landmask_imgs object includes a binary version of the original landmask and a dilated version, which helps to cover the complicated near-coastal regions.","category":"page"},{"location":"preprocessing/","page":"Preprocessing","title":"Preprocessing","text":"<img src=\"../assets/landmask_example.png\" width=\"600\" alt=\"Landmask Example\"/>","category":"page"},{"location":"preprocessing/","page":"Preprocessing","title":"Preprocessing","text":"At the top, we have the original landmask TIFF, which has black and gray values. The middle image is the binary image, with land set to 0. At the bottom, we can see the dilated image using the default value of the structuring element. The default has radius 50, which results in a coastal mask of 12.5 km based on the 250 m pixel size of default MODIS imagery.","category":"page"},{"location":"preprocessing/#Cloud-masks","page":"Preprocessing","title":"Cloud masks","text":"","category":"section"},{"location":"preprocessing/","page":"Preprocessing","title":"Preprocessing","text":"Setting thresholds for cloud mask","category":"page"},{"location":"preprocessing/#Image-regularization","page":"Preprocessing","title":"Image regularization","text":"","category":"section"},{"location":"#IceFloeTracker.jl","page":"IceFloeTracker.jl","title":"IceFloeTracker.jl","text":"","category":"section"},{"location":"#Overview","page":"IceFloeTracker.jl","title":"Overview","text":"","category":"section"},{"location":"","page":"IceFloeTracker.jl","title":"IceFloeTracker.jl","text":"IceFloeTracker.jl is a collection of routines and tools for processing remote sensing imagery, identifying sea ice floes, and tracking the displacement and rotation of ice floes across multiple images. It can be used either standalone to create custom processing pathways or with the Ice Floe Tracker Pipeline.","category":"page"},{"location":"","page":"IceFloeTracker.jl","title":"IceFloeTracker.jl","text":"","category":"page"},{"location":"#Algorithm-components","page":"IceFloeTracker.jl","title":"Algorithm components","text":"","category":"section"},{"location":"","page":"IceFloeTracker.jl","title":"IceFloeTracker.jl","text":"The Ice Floe Tracker (IFT) package includes the core functions for the three main steps of the algorithm. These functions can be used independently and can be customized for specific use cases. ","category":"page"},{"location":"#Preprocessing","page":"IceFloeTracker.jl","title":"Preprocessing","text":"","category":"section"},{"location":"","page":"IceFloeTracker.jl","title":"IceFloeTracker.jl","text":"IFT operates on optical satellite imagery. The main functions are designed with \"true color\" and \"false color\" imagery in mind, and have thus far primarily been tested on imagery from the Moderate Resolution Imaging Spectroradiometer (MODIS) from the NASA Aqua and Terra satellites. The preprocessing routines mask land and cloud features, and aim to adjust and sharpen the remainder of the images to amplify the contrast along the edges of sea ice floes. (TBD: Link to main preprocessing page)","category":"page"},{"location":"#Segmentation","page":"IceFloeTracker.jl","title":"Segmentation","text":"","category":"section"},{"location":"","page":"IceFloeTracker.jl","title":"IceFloeTracker.jl","text":"The IFT segmentation functions include functions for semantic segmentation (pixel-by-pixel assignment into predefined categories) and object-based segmentation (groupings of pixels into distinct objects). The semantic segmentation steps use k-means to group pixels into water and ice regions. A combination of watershed functions, morphological operations, and further applications of k-means are used to identify candidate ice floes. (TBD: Link to main segmentation page)","category":"page"},{"location":"#Tracking","page":"IceFloeTracker.jl","title":"Tracking","text":"","category":"section"},{"location":"","page":"IceFloeTracker.jl","title":"IceFloeTracker.jl","text":"Ice floe tracking is carried out by comparing the shapes produced in the segmentation step. Shapes with similar area are rotated until the difference in surface area is minimized, and then the edge shapes are compared using a Ѱ-s curve. If thresholds for correlation and area differences are met, then the floe with the best correlation and smallest area differences are considered matches and the objects are assigned the same label. In the end, trajectories for individual floes are recorded in a dataframe.","category":"page"},{"location":"#Developers","page":"IceFloeTracker.jl","title":"Developers","text":"","category":"section"},{"location":"","page":"IceFloeTracker.jl","title":"IceFloeTracker.jl","text":"IceFloeTracker.jl is a product of the Wilhelmus Lab at Brown University, led by Monica M. Wilhelmus. The original algorithm was developed by Rosalinda Lopez-Acosta during her PhD work at University of California Riverside, advised by Dr. Wilhelmus. The translation of the original Matlab code into the current modular, open source Julia package has been carried out in conjunction with the Center for Computing and Visualization at Brown University. Contributors include Daniel Watkins, Maria Isabel Restrepo, Carlos Paniagua, Tim Divoll, John Holland, and Bradford Roarr.","category":"page"},{"location":"#Citing","page":"IceFloeTracker.jl","title":"Citing","text":"","category":"section"},{"location":"","page":"IceFloeTracker.jl","title":"IceFloeTracker.jl","text":"If you use IceFloeTracker.jl in research, teaching, or elsewhere, please mention the IceFloeTracker package and cite our journal article outlining the algorithm:","category":"page"},{"location":"","page":"IceFloeTracker.jl","title":"IceFloeTracker.jl","text":"Lopez-Acosta et al., (2019). Ice Floe Tracker: An algorithm to automatically retrieve Lagrangian trajectories via feature matching from moderate-resolution visual imagery. Remote Sensing of Environment, 234(111406), doi:10.1016/j.rse.2019.111406.","category":"page"},{"location":"#Papers-using-Ice-Floe-Tracker","page":"IceFloeTracker.jl","title":"Papers using Ice Floe Tracker","text":"","category":"section"},{"location":"","page":"IceFloeTracker.jl","title":"IceFloeTracker.jl","text":"Manucharyan, Lopez-Acosta, and Wilhelmus (2022)*. Spinning ice floes reveal intensification of mesoscale eddies in the western Arctic Ocean. Scientific Reports, 12(7070), doi:10.1038/s41598-022-10712-z\nWatkins, Bliss, Hutchings, and Wilhelmus (2023)*. Evidence of Abrupt Transitions Between Sea Ice Dynamical Regimes in the East Greenland Marginal Ice Zone. Geophysical Research Letters, 50(e2023GL103558), pp. 1-10, doi:10.1029/2023GL103558","category":"page"},{"location":"","page":"IceFloeTracker.jl","title":"IceFloeTracker.jl","text":"*Papers using data from the Matlab implementation of Ice Floe Tracker.","category":"page"},{"location":"#Functions","page":"IceFloeTracker.jl","title":"Functions","text":"","category":"section"},{"location":"#Preprocessing-2","page":"IceFloeTracker.jl","title":"Preprocessing","text":"","category":"section"},{"location":"#IceFloeTracker.Preprocessing.apply_cloudmask-Tuple{AbstractArray{<:Union{ColorTypes.AbstractRGB, ColorTypes.Transparent3{C} where C<:ColorTypes.AbstractRGB, ColorTypes.TransparentRGB}}, AbstractArray{Bool}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Preprocessing.apply_cloudmask","text":"apply_cloudmask(false_color_image, cloudmask)\n\nZero out pixels containing clouds where clouds and ice are not discernable. Arguments should be of the same size.\n\nArguments\n\nimg: RGB, RGBA, or Gray image to be masked\ncloudmask: binary cloudmask with clouds = 1, else = 0\nmodify_channel_1: optional keyword argument for RGB images. If true, set the first channel to 0 in the returned image.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Preprocessing.apply_landmask-Tuple{AbstractMatrix, BitMatrix}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Preprocessing.apply_landmask","text":"apply_landmask(input_image, landmask_binary)\n\nZero out pixels in all channels of the input image using the binary landmask.\n\nArguments\n\ninput_image: truecolor RGB image\nlandmask_binary: binary landmask with 1=land, 0=water/ice\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Preprocessing.apply_landmask-Tuple{Any, Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Preprocessing.apply_landmask","text":"apply_landmask(img, landmask; as_indices::Bool=false)\n\nApply the landmask to the input image, optionally returning the indices of non-masked (ocean/ice) pixels.\n\nArguments\n\nimg: input image (e.g., ice mask or RGB image)\nlandmask: binary landmask (1=ocean/ice, 0=land)\nas_indices: if true, return indices of non-masked pixels; otherwise, return masked image\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Preprocessing.create_cloudmask","page":"IceFloeTracker.jl","title":"IceFloeTracker.Preprocessing.create_cloudmask","text":"create_cloudmask(img, f::AbstractCloudMaskAlgorithm)\n\nCloud masks in the IFT are BitMatrix objects such that for an image I and cloudmask C, cloudy pixels can be selected by I[C], and clear-sky pixels can be selected with I[.!C]. Construction of a cloud mask uses the syntax\n\nf = CloudMaskAlgorithm(parameters)\nC = create_cloudmask(img; CloudMaskAlgorithm)\n\nBy default, create_cloudmask uses the algorithm found in [1]. This algorithm converts a 3-channel MODIS 7-2-1 false color image into a 1-channel binary matrix in which clouds = 1 and anything else = 0. The algorithm aims to identify patches of opaque cloud while allowing thin and transparent cloud to remain. This algorithm is instantiated using\n\nf = LopezAcostaCloudMask()\n\nIn this case, the default values are applied. It can also called using a set of customized parameters. These values must be real numbers between 0 and 1. To reproduce the default parameters, you may call\n\nf = LopezAcostaCloudMask(prelim_threshold=110/255, band_7_threshold=200/255, band_2_threshold=190/255, ratio_lower=0.0, ratio_upper=0.75).\n\nA stricter cloud mask was defined in [2], covering more cloudy pixels while minimally impacting the masking of cloud-covered ice pixels.\n\nf = LopezAcostaCloudMask(prelim_threshold=53/255, band_7_threshold=130/255, band_2_threshold=169/255, ratio_lower=0.0, ratio_upper=0.53).\n\nThese parameters together define a piecewise linear partition of pixels based on their Band 7 and Band 2 callibrated reflectance. Pixels with intensity above prelim_threshold are considered as potential cloudy pixels. Then, pixels with Band 7 reflectance less than band_7_threshold, Band 2 reflectance greater than band_2_threshold, and Band 7 to Band 2 ratios between ratio_lower and ratio_upper are removed from the cloud mask (i.e., set to cloud-free).\n\nArguments\n\nfalse_color_image: corrected reflectance false color image - bands [7,2,1]\nprelim_threshold: threshold value used to identify clouds in band 7, N0f8(RGB intensity/255)\nband_7_threshold: threshold value used to identify cloud-ice in band 7, N0f8(RGB intensity/255)\nband_2_threshold: threshold value used to identify cloud-ice in band 2, N0f8(RGB intensity/255)\nratio_lower: threshold value used to set lower ratio of cloud-ice in bands 7 and 2\nratio_upper: threshold value used to set upper ratio of cloud-ice in bands 7 and 2\nratio_offset: offset value used to adjust the upper ratio of cloud-ice in bands 7 and 2\n\nLopez-Acosta, R., Schodlok, M. P., & Wilhelmus, M. M. (2019). Ice Floe Tracker: An algorithm to automatically retrieve Lagrangian trajectories via feature matching from moderate-resolution visual imagery. Remote Sensing of Environment, 234(111406), 1–15. (https://doi.org/10.1016/j.rse.2019.111406)[https://doi.org/10.1016/j.rse.2019.111406]\nWatkins, D.M., Kim, M., Paniagua, C., Divoll, T., Holland, J.G., Hatcher, S., Hutchings, J.K., and Wilhelmus, M.M. (in prep). Calibration and validation of the Ice Floe Tracker algorithm. \n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Preprocessing.create_landmask-Union{Tuple{T}, Tuple{T, AbstractMatrix{Bool}}} where T<:(AbstractMatrix)","page":"IceFloeTracker.jl","title":"IceFloeTracker.Preprocessing.create_landmask","text":"create_landmask(landmask_image, struct_elem, fill_value_lower, fill_value_upper)\n\nConvert a land mask image to a 1-channel binary matrix, and use a structuring element to extend a buffer to mask complex coastal features, and fill holes in the dilated image. In the resulting mask, land = 0 and ocean = 1. Returns a named tuple with the dilated and non-dilated landmask.\n\nArguments\n\nlandmask_image: RGB land mask image from fetchdata\nstruct_elem: structuring element for dilation (optional)\nfill_value_lower: fill holes having at least these many pixels (optional)\nfill_value_upper: fill holes having at most these many pixels (optional)\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Preprocessing.make_landmask_se","page":"IceFloeTracker.jl","title":"IceFloeTracker.Preprocessing.make_landmask_se","text":"make_landmask_se()\n\nCreate a structuring element for dilating the landmask.\n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Preprocessing.LopezAcostaCloudMask-Tuple{AbstractArray{<:Union{ColorTypes.AbstractRGB, ColorTypes.Transparent3{C} where C<:ColorTypes.AbstractRGB, ColorTypes.TransparentRGB}}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Preprocessing.LopezAcostaCloudMask","text":"LopezAcostaCloudMask(prelim_threshold, band_7_threshold, band_2_threshold, ratio_lower, ratio_offset, ratio_upper)\n\nAbstractCloudMaskAlgorithm implementation of the cloud mask from Lopez-Acosta et al. 2019. Cloud masks algorithms are initialized with a set of parameters, then can be supplied to create_cloudmask as an argument. The Lopez-Acosta et al. cloudmask creates a piecewise linear bifurcation of band 2 and band 7 brightness in a MODIS 7-2-1 false color image using a sequence of thresholds on band 2 and band 7 and on the ratio of band 7 to band 2 brightness. \n\nExample:\n\nusing IceFloeTracker\nusing IceFloeTracker: Watkins2025GitHub\n\ndata_loader = Watkins2025GitHub(; ref=\"a451cd5e62a10309a9640fbbe6b32a236fcebc70\")\ncase = first(data_loader(c -> (c.case_number == 6 && c.satellite == \"terra\")))\ncm_algo = LopezAcostaCloudMask()\ncloud_mask = create_cloudmask(case.modis_falsecolor, cm_algo)\n\n# show image:\nGray.(cloud_mask)\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Preprocessing.Watkins2025CloudMask-Tuple{AbstractArray{<:Union{ColorTypes.AbstractRGB, ColorTypes.Transparent3{C} where C<:ColorTypes.AbstractRGB, ColorTypes.TransparentRGB}}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Preprocessing.Watkins2025CloudMask","text":"Watkins2025CloudMask(prelimthreshold, band7threshold, band2threshold, ratiolower, ratiooffset, ratioupper, markerstrel, openingstrel)\n\nExtension of the Lopez-Acosta et al. 2019 with parameters calibrated to the Ice Floe Validation Dataset. The Lopez-Acosta et al. cloudmask creates a piecewise linear bifurcation of band 2 and band 7 brightness  in a MODIS 7-2-1 false color image using a sequence of thresholds on band 2 and band 7 and on the ratio of band 7 to band 2 brightness. This extension first creates a cloud mask using the LopezAcostaCloudMask, then applies morphological operations to remove speckle and smooth boundaries.\n\nExample:\n\nusing IceFloeTracker\nusing IceFloeTracker: Watkins2025GitHub\n\ndata_loader = Watkins2025GitHub(; ref=\"a451cd5e62a10309a9640fbbe6b32a236fcebc70\")\ncase = first(data_loader(c -> (c.case_number == 6 && c.satellite == \"terra\")))\ncm_algo = Watkins2025CloudMask()\ncloud_mask = create_cloudmask(case.modis_falsecolor, cm_algo)\n\n# show image:\nGray.(cloud_mask)\n\n\n\n\n\n","category":"method"},{"location":"#Segmentation-2","page":"IceFloeTracker.jl","title":"Segmentation","text":"","category":"section"},{"location":"#IceFloeTracker.Segmentation.IceDetectionLopezAcosta2019-Tuple{}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.IceDetectionLopezAcosta2019","text":"IceDetectionLopezAcosta2019(;\n    band_7_threshold::Float64=Float64(5 / 255),\n    band_2_threshold::Float64=Float64(230 / 255),\n    band_1_threshold::Float64=Float64(240 / 255),\n    band_7_threshold_relaxed::Float64=Float64(10 / 255),\n    band_1_threshold_relaxed::Float64=Float64(190 / 255),\n    possible_ice_threshold::Float64=Float64(75 / 255),\n)\n\nReturns the first non-zero result of two threshold-based and one brightness-peak based ice detections.\n\nDefault thresholds are defined in the published Ice Floe Tracker article: Remote Sensing of the Environment 234 (2019) 111406.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Segmentation.addlatlon!-Tuple{DataFrames.DataFrame, AbstractString}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.addlatlon!","text":"addlatlon(pairedfloesdf::DataFrame, refimage::AbstractString)\n\nAdd columns latitude, longitude, and pixel coordinates x, y to pairedfloesdf.\n\nArguments\n\npairedfloesdf: dataframe containing floe tracking data.\nrefimage: path to reference image.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Segmentation.binarize_segments-Tuple{ImageSegmentation.SegmentedImage}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.binarize_segments","text":"Find pixels in a segmented image with non-zero labels\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Segmentation.convertcentroid!-Tuple{Any, Any, Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.convertcentroid!","text":"convertcentroid!(propdf, latlondata, colstodrop)\n\nConvert the centroid coordinates from row and column to latitude and longitude dropping unwanted columns specified in colstodrop for the output data structure. Addionally, add columns x and y with the pixel coordinates of the centroid.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Segmentation.converttounits!-Tuple{Any, Any, Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.converttounits!","text":"converttounits!(propdf, latlondata, colstodrop)\n\nConvert the floe properties from pixels to kilometers and square kilometers where appropiate. Also drop the columns specified in colstodrop.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Segmentation.find_ice_labels-Tuple{Matrix{ColorTypes.RGB{Float64}}, BitMatrix}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.find_ice_labels","text":"find_ice_labels(falsecolor_image, landmask; band_7_threshold, band_2_threshold, band_1_threshold, band_7_relaxed_threshold, band_1_relaxed_threshold, possible_ice_threshold)\n\nReturns pixel indices of likely ice from false color reflectance image, using the thresholds from the Ice Floe Tracker article: Remote Sensing of the Environment 234 (2019) 111406.\n\nArguments\n\nfalsecolor_image: corrected reflectance false color image - bands [7,2,1]\nlandmask: bitmatrix landmask for region of interest\nband_7_threshold: threshold value used to identify ice in band 7, N0f8(RGB intensity/255)\nband_2_threshold: threshold value used to identify ice in band 2, N0f8(RGB intensity/255)\nband_1_threshold: threshold value used to identify ice in band 2, N0f8(RGB intensity/255)\nband_7_relaxed_threshold: threshold value used to identify ice in band 7 if not found on first pass, N0f8(RGB intensity/255)\nband_1_relaxed_threshold: threshold value used to identify ice in band 1 if not found on first pass, N0f8(RGB intensity/255)\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Segmentation.get_ice_masks-Tuple{AbstractArray{<:Union{ColorTypes.AbstractRGB, ColorTypes.Transparent3{C} where C<:ColorTypes.AbstractRGB, ColorTypes.TransparentRGB}}, AbstractArray{<:ColorTypes.AbstractGray}, AbstractArray{<:Bool}, AbstractMatrix{Tuple{UnitRange{Int64}, UnitRange{Int64}}}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.get_ice_masks","text":"get_ice_masks(\n    falsecolor_image,\n    morph_residue,\n    landmask,\n    tiles,\n    binarize;\n    band_7_threshold,\n    band_2_threshold,\n    band_1_threshold,\n    band_7_threshold_relaxed,\n    band_1_threshold_relaxed,\n    possible_ice_threshold,\n    k\n)\n\nIdentifies potential sea ice floes using two methods: selection of a relevant k-means cluster and application of adaptive threshold binarization. For the k-means section, a series of thresholds on band 7, 2, and 1 reflectance  are applied in order to find the cluster containing bright sea ice pixels.\n\nArguments\n\nfalsecolor_image: MODIS False Color Bands 7-2-1.\nmorph_residue: Grayscale sharpened and equalized image from preprocessing workflow.\nlandmask: Binary landmask. \ntiles: Iterable with tile divisions.\nbinarize::Bool=true: Whether to binarize the tiling.\nband_7_threshold=5/255: The threshold for band 7.\nband_2_threshold=230/255: The threshold for band 2.\nband_1_threshold=240/255: The threshold for band 1.\nband_7_threshold_relaxed=10: The relaxed threshold for band 7.\nband_1_threshold_relaxed=190: The relaxed threshold for band 1.\npossible_ice_threshold=75/255: The threshold for possible ice.\nk=4: The number of clusters to use for k-means segmentation.\n\nReturns\n\nBinary image with likely sea ice floes = 1.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Segmentation.get_ice_peaks-Tuple{Any, Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.get_ice_peaks","text":"Given the edges and counts from build_histogram, identify local maxima and return the location of the largest local maximum that is bright enough that it is possibly sea ice. Locations are determined by  the edges, which by default are the left bin edges. Note also that peaks defaults to the left side of plateaus. Returns Inf if there are no non-zero parts of the histogram with bins larger than the possible ice threshold, or if there are no detected peaks larger than the minimum prominence.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Segmentation.kmeans_segmentation","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.kmeans_segmentation","text":"kmeans_segmentation(gray_image, ice_labels;)\n\nApply k-means segmentation to a gray image to isolate a cluster group representing sea ice. Returns a binary image with ice segmented from background.\n\nArguments\n\ngray_image: output image from ice-water-discrimination.jl or gray ice floe leads image in segmentation_f.jl\nice_labels: vector if pixel coordinates output from find_ice_labels.jl\n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Segmentation.regionprops","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.regionprops","text":"regionprops(label_img, ; properties, connectivity)\n\nA wrapper of the regionprops function from the skimage python library.\n\nSee its full documentation at https://scikit-image.org/docs/stable/api/skimage.measure.html#skimage.measure.regionprops.\n\nArguments\n\nlabel_img: Image with the labeled objects of interest\nintensity_img: (Optional) Used for generating extra_properties, integer/float array from which (presumably) label_img was generated\nextra_properties: (Optional) not yet implemented. It will be set to nothing\n\nSee also regionprops_table\n\nExamples\n\njulia> Random.seed!(123);\n\njulia> bw_img = rand([0, 1], 5, 10)\n5×10 Matrix{Int64}:\n 1  0  1  0  0  0  0  0  0  1\n 1  0  1  1  1  0  0  0  1  1\n 1  1  0  1  1  0  1  0  0  1\n 0  1  0  1  0  0  0  0  1  0\n 1  0  0  0  0  1  0  1  0  1\n\n julia> label_img = Images.label_components(bw_img, trues(3,3))\n 5×10 Matrix{Int64}:\n  1  0  1  0  0  0  0  0  0  4\n  1  0  1  1  1  0  0  0  4  4\n  1  1  0  1  1  0  3  0  0  4\n  0  1  0  1  0  0  0  0  4  0\n  1  0  0  0  0  2  0  4  0  4\n\n julia> regions = regionprops(label_img, bw_img);\n\n julia> for region in regions\n           println(region.area,\"\t\", region.perimeter)\n        end\n13      11.621320343559642\n1       0.0\n1       0.0\n7       4.621320343559642\n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Segmentation.regionprops_table","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.regionprops_table","text":"regionprops_table(label_img, intensity_img; properties, connectivity, extra_properties)\n\nA wrapper of the regionprops_table function from the skimage python library.\n\nSee its full documentation at https://scikit-image.org/docs/stable/api/skimage.measure.html#regionprops-table.\n\nArguments\n\nlabel_img: Image with the labeled objects of interest\nintensity_img: (Optional) Used for generating extra_properties, integer/float array from which (presumably) label_img was generated \nproperties: List (Vector or Tuple) of properties to be generated for each connected component in label_img\nextra_properties: (Optional) not yet implemented. It will be set to nothing\n\nNotes\n\nZero indexing has been corrected for the bbox and centroid properties\nbbox data (max_col and max_row) are inclusive\ncentroid data are rounded to the nearest integer\n\nSee also regionprops\n\nExamples\n\njulia> using IceFloeTracker, Random, Images\n\njulia> Random.seed!(123);\n\njulia> bw_img = rand([0, 1], 5, 10)\n5×10 Matrix{Int64}:\n 1  0  1  0  0  0  0  0  0  1\n 1  0  1  1  1  0  0  0  1  1\n 1  1  0  1  1  0  1  0  0  1\n 0  1  0  1  0  0  0  0  1  0\n 1  0  0  0  0  1  0  1  0  1\n\njulia> label_img = label_components(bw_img, trues(3,3))\n5×10 Matrix{Int64}:\n 1  0  1  0  0  0  0  0  0  4\n 1  0  1  1  1  0  0  0  4  4\n 1  1  0  1  1  0  3  0  0  4\n 0  1  0  1  0  0  0  0  4  0\n 1  0  0  0  0  2  0  4  0  4\n\njulia> properties = [\"area\", \"perimeter\"]\n2-element Vector{String}:\n \"area\"\n \"perimeter\"\n\n julia> regionprops_table(label_img, bw_img, properties = properties)\n 4×2 DataFrame\n  Row │ area   perimeter \n      │ Int32  Float64   \n ─────┼──────────────────\n    1 │    13   11.6213\n    2 │     1    0.0\n    3 │     1    0.0\n    4 │     7    4.62132\n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Segmentation.segmentation_comparison-Tuple{Union{Nothing, ImageSegmentation.SegmentedImage}, Union{Nothing, ImageSegmentation.SegmentedImage}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.segmentation_comparison","text":"function segmentationcomparison(     validated::SegmentedImage, measured::SegmentedImage )::@NamedTuple{recall::Real, precision::Real, Fscore::Real}\n\nCompares two SegmentedImages and returns values describing how similar the segmentations are.\n\nThis treats the segment labeled 0 as background.\n\nMeasures:\n\nprecision: rate at which pixels in validated segments belong to measured segments\nrecall: rate at which pixels in measured segments belong to validated segments\nF_score: harmonic mean of precision and recall\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Segmentation.tiled_adaptive_binarization-Tuple{Any, Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.tiled_adaptive_binarization","text":"tiledadaptivebinarization(img, tiles; minimumwindowsize=). \n\nApplies the (AdaptiveThreshold)[https://juliaimages.org/ImageBinarization.jl/v0.1/#Adaptive-Threshold-1] binarization algorithm\nto each tile in the image. Following the recommendations from ImageBinarization, the default is to use the integer window size\nnearest to 1/8th the tile size if the tile is large enough. So that the window is large enough to include moderately large floes,\nthe default minimum window size is 100 pixels (25 km for MODIS imagery). The minimum brightness parameter masks pixels with low\ngrayscale intensity to prevent dark regions from getting brightened (i.e., the center of a large patch of open water).\nThe \"threshold_percentage\" parameter is passed to the the AdaptiveThreshold function (percentage parameter).\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Segmentation.IceDetectionAlgorithm","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.IceDetectionAlgorithm","text":"IceDetectionAlgorithm\n\nFunctors to detect ice regions in an image.\n\nEach algorithm a with parameters kwargs... can be called like:\n\nbinarize(image, a(; kwargs...)) \nor a(; kwargs...)(image).\n\n\n\n\n\n","category":"type"},{"location":"#IceFloeTracker.Segmentation.IceDetectionBrightnessPeaksMODIS721","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.IceDetectionBrightnessPeaksMODIS721","text":"IceDetectionBrightnessPeaksMODIS721(;\n    band_7_threshold::Real,\n    possible_ice_threshold::Real\n)(image)\nbinarize(\n    modis_721_image, \n    a::IceDetectionBrightnessPeaksMODIS721\n)\n\nReturns pixels for a MODIS image where (band7 < threshold AND both (band2, band_1) are are above a peak value above some threshold).\n\n\n\n\n\n","category":"type"},{"location":"#IceFloeTracker.Segmentation.IceDetectionFirstNonZeroAlgorithm","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.IceDetectionFirstNonZeroAlgorithm","text":"IceDetectionFirstNonZeroAlgorithm(;\n    algorithms::Vector{IceDetectionAlgorithm},\n)(image)\nbinarize(image, algorithms::IceDetectionFirstNonZeroAlgorithm)\n\nRuns each algorithm from algorithms on the image, and returns the first which detects any ice.\n\n\n\n\n\n","category":"type"},{"location":"#IceFloeTracker.Segmentation.IceDetectionThresholdMODIS721","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.IceDetectionThresholdMODIS721","text":"IceDetectionThresholdMODIS721(;\n    band_7_threshold::Real,\n    band_2_threshold::Real,\n    band_1_threshold::Real,\n)(image)\nbinarize(\n    modis_721_image, \n    a::IceDetectionThresholdMODIS721\n)\n\nReturns pixels for a MODIS image where (band7 < threshold AND band2 > threshold AND band_1 > threshold).\n\n\n\n\n\n","category":"type"},{"location":"#IceFloeTracker.Segmentation.SegmentationComparison","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.SegmentationComparison","text":"Results of a segmentation comparison\n\n\n\n\n\n","category":"type"},{"location":"#IceFloeTracker.Segmentation.SegmentationSummary","page":"IceFloeTracker.jl","title":"IceFloeTracker.Segmentation.SegmentationSummary","text":"Results of a segmentation comparison\n\n\n\n\n\n","category":"type"},{"location":"#Tracking-2","page":"IceFloeTracker.jl","title":"Tracking","text":"","category":"section"},{"location":"#IceFloeTracker.Tracking.add_passtimes!-Tuple{Any, Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.add_passtimes!","text":"add_passtimes!(props, passtimes)\n\nAdd a column passtime to each DataFrame in props containing the time of the image in which the floes were captured.\n\nArguments\n\nprops: array of DataFrames containing floe properties.\npasstimes: array of DateTime objects containing the time of the image in which the floes were captured.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.addfloemasks!-Tuple{DataFrames.DataFrame, Union{BitMatrix, Matrix{<:Integer}}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.addfloemasks!","text":"addfloemasks!(props::DataFrame, floeimg::FloeLabelsImage)\n\nAdd a column to props called floearray containing the cropped floe masks from floeimg.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.adduuid!-Tuple{DataFrames.DataFrame}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.adduuid!","text":"adduuid!(df::DataFrame)\nadduuid!(dfs::Vector{DataFrame})\n\nAssign a unique ID to each floe in a (vector of) table(s) of floe properties.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.addψs!-Tuple{Vector{DataFrames.DataFrame}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.addψs!","text":"addψs!(props::Vector{DataFrame})\n\nAdd the ψ-s curves to each member of props.\n\nNote: each member of props must have a mask column with a binary image representing the floe.\n\nTo add floe masks see addfloemasks!.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.align_centroids-Tuple{AbstractArray{Bool}, AbstractArray{Bool}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.align_centroids","text":"Align images by padding so that the centroids of each image are on the edge of or within the same pixel.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.bwtraceboundary-Union{Tuple{Union{Matrix{Float64}, Matrix{Int64}, Matrix{UInt8}, T}}, Tuple{T}} where T<:AbstractMatrix{Bool}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.bwtraceboundary","text":"bwtraceboundary(image::Union{Matrix{Int64},Matrix{Float64},T};\n                P0::Union{Tuple{Int,Int},CartesianIndex{2},Nothing}=nothing,\n                closed::Bool=true) where T<:AbstractMatrix{Bool}\n\nTrace the boundary of objects in image \n\nBackground pixels are represented as zero. The algorithm traces the boundary counterclockwise and an initial point P0 can be specified. If more than one boundary is detected and an initial point is provided, the boundary that contains this point is returned as a vector of CartesianIndex types. Otherwise an array of vectors is returned with all the detected boundaries in image. \n\nArguments\n\nimage: image, preferably binary with one single object, whose objects' boundaries are to be traced.\nP0: initial point of a target boundary.\nclosed: if true (default) makes the inital point of a boundary equal to the last point.\n\nExample\n\njulia> A = zeros(Int, 13, 16); A[2:6, 2:6] .= 1; A[4:8, 7:10] .= 1; A[10:12,13:15] .= 1; A[10:12,3:6] .= 1;\n\njulia> A\n13×16 Matrix{Int64}:\n 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n 0  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0\n 0  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0\n 0  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0\n 0  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0\n 0  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0\n 0  0  0  0  0  0  1  1  1  1  0  0  0  0  0  0\n 0  0  0  0  0  0  1  1  1  1  0  0  0  0  0  0\n 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n 0  0  1  1  1  1  0  0  0  0  0  0  1  1  1  0\n 0  0  1  1  1  1  0  0  0  0  0  0  1  1  1  0\n 0  0  1  1  1  1  0  0  0  0  0  0  1  1  1  0\n 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n\njulia> boundary = IceFloeTracker.bwtraceboundary(A);\n\njulia> boundary[3]\n9-element Vector{CartesianIndex}:\n CartesianIndex(10, 13)\n CartesianIndex(11, 13)\n CartesianIndex(12, 13)\n CartesianIndex(12, 14)\n CartesianIndex(12, 15)\n CartesianIndex(11, 15)\n CartesianIndex(10, 15)\n CartesianIndex(10, 14)\n CartesianIndex(10, 13)\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.compute_centroid-Tuple{AbstractArray{Bool}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.compute_centroid","text":"Calculate the centroid of a binary image. If 'rounded', return the nearest integer.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.cropfloe-Tuple{Union{BitMatrix, Matrix{<:Integer}}, DataFrames.DataFrame, Integer}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.cropfloe","text":"cropfloe(floesimg, props, i)\n\nCrops the floe delimited by the bounding box data in props at index i from the floe image floesimg.\n\nIf the dataframe has bounding box data min_row, min_col, max_row, max_col, but no label, then returns the largest contiguous component.\n\nIf the dataframe has bounding box data min_row, min_col, max_row, max_col, and a label, then returns the component with the label. In this case, floesimg must be an Array{Int}.\n\nIf the dataframe has only a label and no bounding box data, then returns the component with the label, padded by one cell of zeroes on all sides. In this case, floesimg must be an Array{Int}.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.cropfloe-Union{Tuple{I}, Tuple{BitMatrix, Vararg{I, 4}}} where I<:Integer","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.cropfloe","text":"cropfloe(floesimg, min_row, min_col, max_row, max_col)\n\nCrops the floe delimited by min_row, min_col, max_row, max_col, from the floe image floesimg.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.cropfloe-Union{Tuple{J}, Tuple{I}, Tuple{Matrix{I}, J, J, J, J, I}} where {I<:Integer, J<:Integer}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.cropfloe","text":"cropfloe(floesimg, min_row, min_col, max_row, max_col, label)\n\nCrops the floe from floesimg with the label label, returning the region bounded by min_row, min_col, max_row, max_col, and converting to a BitMatrix.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.crosscorr-Union{Tuple{T}, Tuple{Vector{T}, Vector{T}}} where T<:Real","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.crosscorr","text":"r, lags = crosscorr(u::Vector{T},\n                    v::Vector{T};\n                    normalize::Bool=false,\n                    padmode::Symbol=:longest)\n\nWrapper of DSP.xcorr with normalization (see https://docs.juliadsp.org/stable/convolutions/#DSP.xcorr)\n\nReturns the pair (r, lags) with the cross correlation scores r and corresponding lags according to padmode.\n\nArguments\n\nu,v: real vectors which could have unequal length.\nnormalize: return normalized correlation scores (false by default).\npadmode: either :longest (default) or :none to control padding of shorter vector with zeros.\n\nExamples\n\nThe example below builds two vectors, one a shifted version of the other, and computes various cross correlation scores.\n\njulia> n = 1:5;\n\njulia> x = 0.48.^n;\n\njulia> y = circshift(x,3);\n\njulia> r, lags = crosscorr(x,y,normalize=true);\n\njulia> [r lags]\n9×2 Matrix{Float64}:\n0.369648    -4.0\n0.947531    -3.0\n0.495695    -2.0\n0.3231      -1.0\n0.332519     0.0\n0.15019      1.0\n0.052469     2.0\n0.0241435    3.0\n0.00941878   4.0\n\njulia> r, lags = crosscorr(x,y,normalize=true,padmode=:none);\n\njulia> [r lags]\n9×2 Matrix{Float64}:\n0.369648    1.0\n0.947531    2.0\n0.495695    3.0\n0.3231      4.0\n0.332519    5.0\n0.15019     6.0\n0.052469    7.0\n0.0241435   8.0\n0.00941878  9.0\n\nThis final example builds two vectors of different length and computes some cross correlation scores.\n\njulia> n = 1:5; m = 1:3;\n\njulia> x = 0.48.^n; y = 0.48.^m;\n\njulia> r, lags = crosscorr(x,y,normalize=true);\n\njulia> [r lags]\n9×2 Matrix{Float64}:\n0.0          -4.0\n4.14728e-17  -3.0\n0.178468     -2.0\n0.457473     -1.0\n0.994189      0.0\n0.477211      1.0\n0.229061      2.0\n0.105402      3.0\n0.0411191     4.0\n\njulia> r, lags = crosscorr(x,y,normalize=true,padmode=:none);\n\njulia> [r lags]\n7×2 Matrix{Float64}:\n0.178468   1.0\n0.457473   2.0\n0.994189   3.0\n0.477211   4.0\n0.229061   5.0\n0.105402   6.0\n0.0411191  7.0\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.get_rotation_measurements-Tuple{DataFrames.DataFrameRow, DataFrames.DataFrameRow}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.get_rotation_measurements","text":"Calculate the angle and rotation rate between two observations in DataFrameRows row1 and row2. image_column and time_column specify which columns to use from the DataFrameRows. registration_function is used to compare the two images and should return an angle. Returns a NamedTuple with the angle theta_rad, time difference dt_sec and rotation rate omega_rad_per_sec, and the two input rows.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.get_rotation_measurements-Tuple{DataFrames.DataFrameRow, DataFrames.DataFrame}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.get_rotation_measurements","text":"Calculate the angle and rotation rate between a measurement in a DataFrameRow measurement, and all the other rows in DataFrame df.\n\nimage_column is the column with the image to compare, \ntime_column is the column with the timepoint of each observation,\nregistration_function is used to compare the two images and should return an angle.\n\nReturns a vector of NamedTuples with one entry for each comparison, with the angle theta_rad, time difference dt_sec and rotation rate omega_rad_per_sec, and the two input rows for each comparison row1 and row2.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.get_rotation_measurements-Tuple{DataFrames.DataFrame}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.get_rotation_measurements","text":"Calculate the angle and rotation rate between observations in DataFrame df.\n\nid_column is the column with the ID of the image over several observations, e.g. the floe ID.\nimage_column is the column with the image to compare, \ntime_column is the column with the timepoint of each observation,\nregistration_function is used to compare the two images and should return an angle.\n\nEach row is compared to each other row in df which are:\n\nfor the same object ID,\nstrictly older,\nnot older than the previous day.\n\nReturns a DataFrame with one row for each comparison, with the angle theta_rad, time difference dt_sec and rotation rate omega_rad_per_sec, and all the other values from df with the column name suffix 1 for the first observation and 2 for the second.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.get_rotation_measurements-Union{Tuple{T}, Tuple{AbstractArray, AbstractArray, T, T}} where T<:Union{Dates.DateTime, TimeZones.ZonedDateTime}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.get_rotation_measurements","text":"Calculate the angle and rotation rate between two images image1 and image2 at times time1 and time2. Returns a NamedTuple with the angle theta_rad, time difference dt_sec and rotation rate omega_rad_per_sec. registration_function is used to compare the two images and should return an angle.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.get_trajectory_heads-Tuple{T} where T<:DataFrames.AbstractDataFrame","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.get_trajectory_heads","text":"get_trajectory_heads(pairs)\n\nReturn the last row (most recent member) of each group (trajectory) in pairs as a dataframe.\n\nThis is used for getting the initial floe properties for the next day in search for new pairs.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.grad-Tuple{Matrix{<:Number}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.grad","text":"dx, dy = grad(A::Matrix{<:Number})\n\nMake gradient vector field for the set of points with coordinates in the rows of the matrix A with x-coordinates down column 1 and y-coordinates down column 2. Return a tuple with dx and dy in that order. \n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.grad-Tuple{Vector{<:Number}, Vector{<:Number}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.grad","text":"dx, dy = grad(x::Vector{<:Number}, y::Vector{<:Number})\n\nMake gradient vector field for the set of points with coordinates in vectors x and y. Return a tuple with dx and dy in that order. \n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.long_tracker-Tuple{Vector{DataFrames.DataFrame}, Any, Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.long_tracker","text":"long_tracker(props, condition_thresholds, mc_thresholds)\n\nTrack ice floes over multiple observations.\n\nTrajectories are built as follows:\n\nAssume the floes detected in observation 1 are trajectories of length 1.\nFor each subsequent observation:\nDetermine the latest observation for each trajectory – these are the \"current trajectory heads\".\nFind matches between the the current trajectory heads and the new observed floes, extending those trajectories.\nAny unmatched floe in an observation is added as a new trajectory starting point.\n\nArguments\n\nprops::Vector{DataFrame}: A vector of DataFrames, each containing ice floe properties for a single day. Each DataFrame must have the following columns:\n\"area\"\n\"min_row\"\n\"min_col\"\n\"max_row\"\n\"max_col\"\n\"row_centroid\"\n\"col_centroid\"\n\"convex_area\"\n\"majoraxislength\"\n\"minoraxislength\"\n\"orientation\"\n\"perimeter\"\n\"mask\": 2D array of booleans\n\"passtime\": A timestamp for the floe\n\"psi\": the psi-s curve for the floe\n\"uuid\": a universally unique identifier for each segmented floe\ncandidate_filter_settings: namedtuple of settings and functions for reducing the number of possible matches. See IceFloeTracker.candidate_filter_settings for sample values.\ncandidate_matching_settings: settings for area mismatch and psi-s shape correlation. See IceFloeTracker.candidate_matching_settings for sample values.\n\nReturns\n\nA DataFrame with the above columns, plus extra columns:\n\narea_mismatch and corr, which are the area mismatch and correlation between a floe and the one that preceeds it in the trajectory. \nhead_uuid, the floe which was best matched by this floe.\nTrajectories are identified by: \na unique identifier ID and the \nUUID of the trajectory, trajectory_uuid.\n\nNote: the props dataframes are modified in place.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.make_psi_s-Tuple{Matrix{<:Number}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.make_psi_s","text":"make_psi_s(XY::Matrix{<:Number};rangeout::Bool=true,\nunwrap::Bool=true)\n\nAlternate method of make_psi_s accepting input vectors x and y as a 2-column matrix [x y] in order to facillitate workflow (output from resample_boundary).\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.make_psi_s-Tuple{Vector{<:Number}, Vector{<:Number}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.make_psi_s","text":"make_psi_s(x::Vector{<:Number},\n           y::Vector{<:Number};\n           rangeout::Bool=true,\n           unwrap::Bool=true)::Tuple{Vector{Float64}, Vector{Float64}}\n\nBuilds the ψ-s curve defined by vectors x and y.\n\nReturns a tuple of vectors with the phases ψ in the first component and the traversed arclength in the second component. \n\nFollowing the convention in [1], the wrapped ψ-s curve has values in [0, 2π) by default; use rangeout to control this behavior.\n\nSee also bwtraceboundary, resample_boundary\n\nArguments\n\nx: Vector of x-coordinates\ny: corresponding vector of y-coordinates\nrangeout: true (default) for phase values in [0, 2π); false for phase values in (-π, π].\nunwrap: set to true to get \"unwrapped\" phases (default). \n\nReference\n\n[1] McConnell, Ross, et al. \"psi-s correlation and dynamic time warping: two methods for tracking ice floes in SAR images.\" IEEE Transactions on Geoscience and Remote sensing 29.6 (1991): 1004-1012.\n\nExample\n\nThe example below builds a cardioid and obtains its ψ-s curve.\n\njulia> t = range(0,2pi,201);\n\njulia> x = @. cos(t)*(1-cos(t));\n\njulia> y = @. sin(t)*(1-cos(t));\n\njulia> plot(x,y) # visualize the cardioid\n\njulia> psi, s = make_psi_s(x,y);\n\njulia> [s psi] # inspect psi-s data\n200×2 Matrix{Float64}:\n 0.00049344  0.0314159\n 0.0019736   0.0733034\n 0.00444011  0.11938\n 0.00789238  0.166055\n 0.0123296   0.212929\n 0.0177505   0.259894\n 0.024154    0.306907\n 0.0315383   0.35395\n 0.0399017   0.401012\n 0.0492421   0.448087\n ⋮\n 7.96772     9.02377\n 7.97511     9.07083\n 7.98151     9.11787\n 7.98693     9.16488\n 7.99137     9.21185\n 7.99482     9.25872\n 7.99729     9.3054\n 7.99877     9.35147\n 7.99926     9.39336\n\n julia> plot(s, psi) # inspect psi-s curve -- should be a straight line from (0, 0) to (8, 3π)\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.matchcorr-Union{Tuple{F}, Tuple{S}, Tuple{T}, Tuple{T, T, Any}} where {T<:AbstractMatrix{Bool}, S<:Int64, F<:Float64}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.matchcorr","text":"matchcorr(\nf1::T,\nf2::T,\nΔt::F,\nmxrot::S=10,\npsi::F=0.95,\nsz::S=16,\ncomp::F=0.25,\nmm::F=0.22\n)\nwhere {T<:AbstractArray{Bool,2},S<:Int64,F<:Float64}\n\nCompute the mismatch mm and psi-s-correlation c for floes with masks f1 and f2.\n\nThe criteria for floes to be considered equivalent is as follows:     - c greater than mm      - _mm is less than mm\n\nA pair of NaN is returned for cases for which one of their mask dimension is too small or their sizes are not comparable.\n\nArguments\n\nf1: mask of floe 1\nf2: mask of floe 2\nΔt: time difference between floes\nmxrot: maximum rotation (in degrees) allowed between floes (default: 10)\npsi: psi-s-correlation threshold (default: 0.95)\nsz: size threshold (default: 16)\ncomp: size comparability threshold (default: 0.25)\nmm: mismatch threshold (default: 0.22)\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.mismatch","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.mismatch","text":"mismatch(\n    fixed::AbstractArray,\n    moving::AbstractArray,\n    mxrot::Real,\n    step::Real,\n)\n\nEstimate a rotation that minimizes the 'mismatch' of aligning moving with fixed.\n\nReturns a pair with the mismatch score mm and the associated registration angle rot.\n\nArguments\n\nfixed,moving: images to align via a rigid transformation\nmxrot: maximum rotation angle in degrees\nstep: rotation angle step size in degrees\n\nThe default registration angles are evenly distributed in steps of 5º around a full rotation, ensuring that no angles are repeated (since -180º == +180º).\n\nAngles are ordered so that smaller absolute angles which are positive will be returned in the event of a tie in the shape difference. ```\n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Tracking.mismatch-Tuple{AbstractArray, AbstractArray, AbstractArray}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.mismatch","text":"mismatch(\n    fixed::AbstractArray,\n    moving::AbstractArray,\n    test_angles::AbstractArray,\n)\n\nEstimate a rotation that minimizes the 'mismatch' of aligning moving with fixed.\n\nReturns a pair with the mismatch score mm and the associated registration angle rot.\n\nArguments\n\nfixed,moving: images to align via a rigid transformation\ntest_angles: candidate angles to check for rotations by, in degrees.  In the case of a tie in the shape difference, the earlier angle from this array will be returned.\n\n```\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.norm-Tuple{Vector{<:Number}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.norm","text":"norm(v)\n\nGet the euclidean norm of the vector v.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.register-Tuple{Any, Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.register","text":"Finds the image rotation angle in test_angles which minimizes the shape difference between im_reference and im_target. The default test angles are shown in register_default_angles_rad. Use imrotate_function=imrotate_bin_<clockwise|counterclockwise>_<radians|degrees> to get angles <clockwise|counterclockwise> in <radians|degrees>.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Tracking.resample_boundary","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.resample_boundary","text":"resample_boundary(bd_points::Vector{<:CartesianIndex}, reduc_factor::Int64=2, bd::String=\"natural\")\n\nGet a uniform set of resampled boundary points from bd_points using cubic splines with specified boundary conditions\n\nThe resampled set of points is obtained using parametric interpolation of the points in bd_points. It is assumed that the separation between a pair of adjacent points is 1.\n\nArguments\n\nbd_points: Sequetial set of boundary points for the object of interest\nreduc_factor: Factor by which to reduce the number of points in bd_points (2 by default)\n\n-bd: Boundary condition, either 'natural' (default) or 'periodic'\n\nSee also bwtraceboundary\n\nExample\n\n```jldoctest; setup = :(using IceFloeTracker) julia> A = zeros(Int, 13, 16); A[2:6, 2:6] .= 1; A[4:8, 7:10] .= 1; A[10:12,13:15] .= 1; A[10:12,3:6] .= 1; julia> A 13×16 Matrix{Int64}:  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  0  0  0  0  0  0  1  1  1  0  0  0  1  1  1  1  0  0  0  0  0  0  1  1  1  0  0  0  1  1  1  1  0  0  0  0  0  0  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n\njulia> boundary = bwtraceboundary(A);\n\njulia> boundary[3] 9-element Vector{CartesianIndex}:  CartesianIndex(10, 13)  CartesianIndex(11, 13)  CartesianIndex(12, 13)  CartesianIndex(12, 14)  CartesianIndex(12, 15)  CartesianIndex(11, 15)  CartesianIndex(10, 15)  CartesianIndex(10, 14)  CartesianIndex(10, 13)\n\njulia> resample_boundary(boundary[3]) 4×2 Matrix{Float64}:  10.0     13.0  12.0357  13.5859  10.5859  15.0357  10.0     13.0\n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Tracking.shape_difference_rotation-Tuple{Any, Any, Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Tracking.shape_difference_rotation","text":"Computes the shape difference between imreference and imtarget for each angle in testangles. The reference image is held constant, while the target image is rotated. The testangles are interpreted as the angle of rotation from target to reference, so to find the best match, we rotate the reverse direction. A perfect match at angle A would imply imtarget is the same shape as if imreference was rotated by A.  Use imrotate_function=imrotate_bin_<clockwise|counterclockwise>_<radians|degrees> to get angles <clockwise|counterclockwise> in <radians|degrees>.\n\n\n\n\n\n","category":"method"},{"location":"#Morphology","page":"IceFloeTracker.jl","title":"Morphology","text":"","category":"section"},{"location":"#IceFloeTracker.Morphology.branch-Tuple{T} where T<:(AbstractArray{Bool})","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.branch","text":"branch(img::AbstractArray{Bool})\n\nFind branch points in skeletonized image img according to Definition 3 of [1].\n\n[1] Arcelli, Carlo, and Gabriella Sanniti di Baja. \"Skeletons of planar patterns.\" Machine Intelligence and Pattern Recognition. Vol. 19. North-Holland, 1996. 99-143.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Morphology.bridge-Tuple{T} where T<:(AbstractArray{Bool})","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.bridge","text":"bridge(bw)\n\nSet 0-valued pixels to 1 if they have two nonzero neighbors that are not connected. Note the following exceptions:\n\n0 0 0           0 0 0 1 0 1  becomes  1 1 1 0 0 0           0 0 0\n\n1 0 1           1 1 1 0 0 0  becomes  0 0 0 0 0 0           0 0 0\n\nThe same applies to all their corresponding rotations.\n\nExamples\n\njulia> bw = [0 0 0; 0 0 0; 1 0 1]\n3×3 Matrix{Int64}:\n 0  0  0\n 0  0  0\n 1  0  1\n\njulia> bridge(bw)\n3×3 BitMatrix:\n 0  0  0\n 0  0  0\n 1  1  1\n\njulia> bw = [1 0 0; 1 0 1; 0 0 1]\n3×3 Matrix{Int64}:\n 1  0  0\n 1  0  1\n 0  0  1\n\njulia> bridge(bw)\n3×3 BitMatrix:\n 1  1  0\n 1  1  1\n 0  1  1\n\n julia> bw = [1 0 1; 0 0 0; 1 0 1]\n3×3 Matrix{Int64}:\n 1  0  1\n 0  0  0\n 1  0  1\n\njulia> bridge(bw)\n3×3 BitMatrix:\n 1  1  1\n 1  1  1\n 1  1  1\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Morphology.bwareamaxfilt","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.bwareamaxfilt","text":"bwareamaxfilt(bwimg::AbstractArray{Bool}, conn)\n\nFilter the smaller (by area) connected components in bwimg keeping the (assumed unique) largest.\n\nUses 8-pixel connectivity by default (conn=8). Use conn=4 for 4-pixel connectivity.\n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Morphology.bwareamaxfilt!","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.bwareamaxfilt!","text":"bwareamaxfilt!(bwimg::AbstractArray)\n\nIn-place version of bwareamaxfilt.\n\nSee also bwareamaxfilt \n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Morphology.bwperim-Tuple{T} where T<:AbstractMatrix{Bool}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.bwperim","text":"bwperim(bwimg)\n\nLocate the pixels at the boundary of objects in an binary image bwimg using 8-pixel connectivity.\n\nArguments\n\nbwimg: Binary (black/white – 1/0) image\n\nExamples\n\njulia> A = zeros(Bool, 13, 16); A[2:6, 2:6] .= 1; A[4:8, 7:10] .= 1; A[10:12,13:15] .= 1; A[10:12,3:6] .= 1;\n\njulia> A\n13×16 Matrix{Bool}:\n 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n 0  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0\n 0  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0\n 0  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0\n 0  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0\n 0  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0\n 0  0  0  0  0  0  1  1  1  1  0  0  0  0  0  0\n 0  0  0  0  0  0  1  1  1  1  0  0  0  0  0  0\n 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n 0  0  1  1  1  1  0  0  0  0  0  0  1  1  1  0\n 0  0  1  1  1  1  0  0  0  0  0  0  1  1  1  0\n 0  0  1  1  1  1  0  0  0  0  0  0  1  1  1  0\n 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n\n julia> bwperim(A)\n13×16 Matrix{Bool}:\n 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n 0  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0\n 0  1  0  0  0  1  0  0  0  0  0  0  0  0  0  0\n 0  1  0  0  0  0  1  1  1  1  0  0  0  0  0  0\n 0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0\n 0  1  1  1  1  1  0  0  0  1  0  0  0  0  0  0\n 0  0  0  0  0  0  1  0  0  1  0  0  0  0  0  0\n 0  0  0  0  0  0  1  1  1  1  0  0  0  0  0  0\n 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n 0  0  1  1  1  1  0  0  0  0  0  0  1  1  1  0\n 0  0  1  0  0  1  0  0  0  0  0  0  1  0  1  0\n 0  0  1  1  1  1  0  0  0  0  0  0  1  1  1  0\n 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Morphology.filt_except_label-Tuple{Matrix{Int64}, Int64}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.filt_except_label","text":"filt_except_label(labeled_arr::Array{Int64, 2}, label::Int64)\n\nMake 0 all values in labeled_arr that are not equal to label.\n\nSee also filt_except_label! \n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Morphology.get_areas-Union{Tuple{Matrix{T}}, Tuple{T}} where T","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.get_areas","text":"get_areas(labeled_arr::Array{T, 2})::Dict{T, Int} where T\n\nGet the \"areas\" (count of pixels of a given label) of the connected components in labeled_arr.\n\nReturn a dictionary with the frequency distribution: label => countoflabel.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Morphology.get_max_label-Tuple{Dict{Int64, Int64}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.get_max_label","text":"get_max_label(d::Dict{Int, Int})\n\nGet the label k in dictionary d for which d[k] is maximal.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Morphology.hbreak!-Tuple{T} where T<:(AbstractArray{Bool})","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.hbreak!","text":"hbreak!(img::AbstractArray{Bool})\n\nInplace version of hbreak. See also hbreak.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Morphology.hbreak-Tuple{Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.hbreak","text":"hbreak(img::AbstractArray{Bool})\n\nRemove H-connected pixels in the binary image img. See also hbreak! for an inplace version of this function.\n\nExamples\n\n\njulia> h1 = trues(3,3); h1[[1 3], 2] .= false; h1     \n3×3 BitMatrix:    \n 1  0  1\n 1  1  1\n 1  0  1\n\njulia> h2 = trues(3,3); h2[2, [1 3]] .= false; h2     \n3×3 BitMatrix:    \n 1  1  1\n 0  1  0\n 1  1  1\n\njulia> hbreak!(h1); h1 # modify h1 inplace\n3×3 BitMatrix:\n 1  0  1\n 1  0  1\n 1  0  1\n\njulia> hbreak(h2) \n3×3 BitMatrix:\n 1  1  1\n 0  0  0\n 1  1  1\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Morphology.imextendedmin","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.imextendedmin","text":"imextendedmin(img)\n\nMimics MATLAB's imextendedmin function that computes the extended-minima transform, which is the regional minima of the H-minima transform. Regional minima are connected components of pixels with a constant intensity value. This function returns a transformed bitmatrix.\n\nArguments\n\nimg: image object\nh: suppress minima below this depth threshold\nconn: neighborhood connectivity; in 2D 1 = 4-neighborhood and 2 = 8-neighborhood\n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Morphology.impose_minima-Union{Tuple{T}, Tuple{AbstractArray{T}, AbstractArray{Bool}}} where T<:Integer","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.impose_minima","text":"impose_minima(I::AbstractArray{T}, BW::AbstractArray{Bool}) where {T<:Integer}\n\nUse morphological reconstruction to enforce minima on the input image I at the positions where the binary mask BW is non-zero.\n\nIt supports both integer and grayscale images using different implementations for each.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Morphology.imregionalmin","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.imregionalmin","text":"imregionalmin(img, conn=2)\n\nCompute the regional minima of the image img using the connectivity conn.\n\nReturns a bitmatrix of the same size as img with the regional minima.\n\nArguments\n\nimg: Image object\nconn: Neighborhood connectivity; in 2D, 1 = 4-neighborhood and 2 = 8-neighborhood\n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Morphology.make_hbreak_dict-Tuple{}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.make_hbreak_dict","text":"make_hbreak_dict()\n\nBuild dict with the two versions of an H-connected 3x3 neighboorhood.\n\nh1 =   [1 0 1              1 1 1              1 0 1]    \n\nh2 =   [1 1 1              0 1 0              1 1 1]  \n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Morphology.morph_fill-Tuple{T} where T<:(AbstractArray{Bool})","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.morph_fill","text":"morph_fill(bw::T)::T where {T<:AbstractArray{Bool}}\n\nFill holes in binary image bw by setting 0-valued pixels to 1 if they are surrounded by 1-valued pixels.\n\nExamples\n\njulia> bw = Bool[\n        0 0 0 0 0\n        0 1 1 1 0\n        0 1 0 1 0\n        0 1 1 1 0\n        0 0 0 0 0\n    ];\n\njulia> morph_fill(bw)\n5×5 Matrix{Bool}:\n 0  0  0  0  0\n 0  1  1  1  0\n 0  1  1  1  0\n 0  1  1  1  0\n 0  0  0  0  0\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Morphology.reconstruct","page":"IceFloeTracker.jl","title":"IceFloeTracker.Morphology.reconstruct","text":"reconstruct(img, se, type, invert)\n\nPerform closing/opening by reconstruction on img.\n\nArguments\n\nimg::AbstractArray: The input image.\nse::AbstractArray: The structuring element.\ntype::String: The type of morphological operation to perform. Must be either \"dilation\" (close by reconstruction) or \"erosion\" (open by reconstruction).\ninvert::Bool=true: Invert marker and mask before reconstruction.\n\n\n\n\n\n","category":"function"},{"location":"#Filtering","page":"IceFloeTracker.jl","title":"Filtering","text":"","category":"section"},{"location":"#IceFloeTracker.Filtering.conditional_histeq-Tuple{Any, Any, Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Filtering.conditional_histeq","text":"conditional_histeq(\n    image,\n    clouds_red,\n    tiles;\n    entropy_threshold::Real=4.0,\n    white_threshold::Real=25.5,\n    white_fraction_threshold::Real=0.4,\n)\n\nPerforms conditional histogram equalization on a true color image.\n\nArguments\n\nimage: The true color image to be equalized.\nclouds_red: The land/cloud masked red channel of the false color image.\ntiles: the output from get_tiles(image) specifying the tiling to use on the image.\nentropy_threshold: The entropy threshold used to determine if a block should be equalized. Default is 4.0.\nwhite_threshold: The white threshold used to determine if a pixel should be considered white. Default is 25.5.\nwhite_fraction_threshold: The white fraction threshold used to determine if a block should be equalized. Default is 0.4.\n\nReturns\n\nThe equalized true color image.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Filtering.histeq-Tuple{S} where S<:(AbstractArray{<:Integer})","page":"IceFloeTracker.jl","title":"IceFloeTracker.Filtering.histeq","text":"histeq(img)\nhisteq(img; nbins=64)\n\nHistogram equalization of img using nbins bins.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Filtering.imadjust-Union{Tuple{AbstractArray{<:Integer}}, Tuple{T}} where T<:AbstractFloat","page":"IceFloeTracker.jl","title":"IceFloeTracker.Filtering.imadjust","text":"imadjust(img; low, high)\n\nAdjust the contrast of an image using linear stretching. The image is normalized to [0, 1] and then stretched to the range [low, high].\n\nArguments\n\nimg: The input image.\nlow: The lower bound of the stretched image. Default is 0.01.\nhigh: The upper bound of the stretched image. Default is 0.99.\n\nReturns\n\nThe contrast-adjusted image in the range [0, 255].\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Filtering.nonlinear_diffusion-Tuple{AbstractArray{<:Union{ColorTypes.AbstractRGB, ColorTypes.AbstractGray, ColorTypes.Transparent3{C} where C<:ColorTypes.AbstractRGB, ColorTypes.TransparentRGB}}, Float64, Number, Int64}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Filtering.nonlinear_diffusion","text":"Perform nonlinear diffusion on an input image. By default, use the Perona-Malik method.\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Filtering.rgb2gray-Tuple{Array{Float64, 3}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Filtering.rgb2gray","text":"rgb2gray(rgbchannels::Array{Float64, 3})\n\nConvert an array of RGB channel data to grayscale in the range [0, 255].\n\nIdentical to MATLAB rgb2gray (https://www.mathworks.com/help/matlab/ref/rgb2gray.html).\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Filtering.rgb2gray-Tuple{Matrix{ColorTypes.RGB{Float64}}}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Filtering.rgb2gray","text":"rgb2gray(img::Matrix{RGB{Float64}})\n\nConvert an RGB image to grayscale in the range [0, 255].\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Filtering.unsharp_mask","page":"IceFloeTracker.jl","title":"IceFloeTracker.Filtering.unsharp_mask","text":"unsharp_mask(img, radius, amount, threshold)\n\nEnhance image sharpness by weighted differencing of the image and a Gaussian blurred image.\nIf ``B`` is the blurred version of image ``I``, then an unsharp mask sharpened image is obtained by\n``S = I + (I - B)*A``\nThe amount of sharpening is determined by the factor A. An option threshold can be supplied such\nthat the sharpening is only applied where ``I - B`` is greater than some factor.\n\n# Arguments\nimg: input image\nradius: standard deviation of the Gaussian blur\namount: multiplicative factor\nthreshold: minimum difference for applying the sharpening\n\n# Returns\nSharpened image\n\n\n\n\n\n","category":"function"},{"location":"#IceFloeTracker.Filtering.unsharp_mask-Tuple{Matrix{Int64}, Any, Any, Any}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Filtering.unsharp_mask","text":"unsharp_mask(image_gray, smoothing_param, intensity, clampmax)\n\nApply unsharp masking on (equalized) grayscale ([0, clampmax]) image to enhance its sharpness.\n\nArguments\n\nimage_gray: The input grayscale image, typically already equalized.\nsmoothing_param::Int: The pixel radius for Gaussian blurring (typically between 1 and 10).\nintensity: The amount of sharpening to apply. Higher values result in more pronounced sharpening.\nclampmax: upper limit of intensity values in the returned image.`\n\nReturns\n\nThe sharpened grayscale image with values clipped between 0 and clapmax.\n\n\n\n\n\n","category":"method"},{"location":"#Data","page":"IceFloeTracker.jl","title":"Data","text":"","category":"section"},{"location":"#IceFloeTracker.Data.ValidationDataLoader","page":"IceFloeTracker.jl","title":"IceFloeTracker.Data.ValidationDataLoader","text":"Loader for validated ice floe data.\n\n\n\n\n\n","category":"type"},{"location":"#IceFloeTracker.Data.Watkins2025GitHub","page":"IceFloeTracker.jl","title":"IceFloeTracker.Data.Watkins2025GitHub","text":"Watkins2025GitHub(; ref)()\nWatkins2025GitHub(; ref, [url, dataset_metadata_path, cache_dir])(; [case_filter])\n\nLoader for validated ice floe data from the Watkins 2025 Ice Floe Validation Dataset.\n\nStruct fields: \n\nurl: URL of the GitHub repository with the dataset\nref: git ref of the commit from which to load the data\ndataset_metadata_path: path within the repository to a CSV file describing the data\ncache_dir: local path where the data will be stored.\n\nCacheing:  Data are downloaded to the ref subdirectory of cache_dir, e.g. /tmp/Watkins2025/main.  If a file of the correct name already exists in that path, if loaded again the cached data will be returned. If the data change in the source for that ref, the loader won't load the new data. In that case, it's necessary to delete the cached file. A better choice is to use a specific revision ref: either a tag, or a commit ID.\n\nFunction arguments:\n\ncase_filter: function run on each metadata entry;    if it returns true, then the data from that case is returned \n\nFunction returns a named tuple with these fields:\n\nmetadata: DataFrame of the cases which passed the case_filter\ndata: Generator which returns a ValidationDataCase for each case which passed the case_filter\n\nExample:\n\njulia> data_loader = Watkins2025GitHub(; ref=\"a451cd5e62a10309a9640fbbe6b32a236fcebc70\")\njulia> dataset = data_loader(;case_filter=c -> (\n                        c.visible_floes == \"yes\" &&\n                        c.cloud_category_manual == \"none\" &&\n                        c.artifacts == \"no\"\n                    ));\njulia> dataset.metadata\n8×28 DataFrame\n    Row │ case_number  region        start_date  center_lon  center_lat  center_x  center_y  month  sea_ice_fr ⋯\n        │ Int64        String31      Date        Float64     Float64     Int64     Int64     Int64  Float64    ⋯\n   ─────┼───────────────────────────────────────────────────────────────────────────────────────────────────────\n      1 │          11  baffin_bay    2011-07-02    -70.7347     72.3303   -837500  -1737500      7             ⋯\n      2 │          14  baffin_bay    2022-07-06    -69.0755     72.3157   -787500  -1762500      7\n      3 │          48  beaufort_sea  2021-04-27   -140.612      70.1346  -2162500    212500      4\n      4 │          48  beaufort_sea  2021-04-27   -140.612      70.1346  -2162500    212500      4\n      5 │          54  beaufort_sea  2015-05-16   -136.675      70.4441  -2137500     62500      5             ⋯\n      6 │          54  beaufort_sea  2015-05-16   -136.675      70.4441  -2137500     62500      5\n      7 │         128  hudson_bay    2019-04-15    -91.9847     57.853   -2612500  -2437500      4\n      8 │         166  laptev_sea    2016-09-04    136.931      79.7507    -37500   1112500      9\n                                                                                        20 columns omitted\n\njulia> first(dataset.data)\nValidationDataCase(\"011-baffin_bay-100km-20110702-aqua-250m\", Dict{Symbol, Any}(:sea_ice_fraction => 0.8, :vi...\n\njulia> first(dataset.data).validated_labeled_floes\nSegmented Image with:\nlabels map: 400×400 Matrix{Int64}\nnumber of labels: 105\n\n\n\n\n\n","category":"type"},{"location":"#Utils","page":"IceFloeTracker.jl","title":"Utils","text":"","category":"section"},{"location":"#IceFloeTracker.Utils.callable_store-Tuple{}","page":"IceFloeTracker.jl","title":"IceFloeTracker.Utils.callable_store","text":"callable_store()\n\nCreate a store and a callback function to add key-value pairs to the store.\n\nReturns a store::Dict and a callback::Function which stores any kwargs passed to it in the store.\n\nExamples\n\nBasic usage is to store values using the callback function\n\njulia> store, callback = callable_store()\njulia> store\nDict{Any, Any}()\n\njulia> callback(;foo=\"bar\")  # echoes the updated store\nDict{Any, Any} with 1 entry:\n  :foo => \"bar\"\n\njulia> store  # values are available from the store object\nDict{Any, Any} with 1 entry:\n  :foo => \"bar\"\n\nA real-world use case is to extract data from a segmentation algorithm run:\n\njulia> intermediate_results, intermediate_results_callback = callable_store()\njulia> data = first(Watkins2025GitHub(; ref=\"a451cd5e62a10309a9640fbbe6b32a236fcebc70\")());\njulia> segments = LopezAcosta2019Tiling.Segment()(\n    data.modis_truecolor,\n    data.modis_falsecolor,\n    data.modis_landmask;\n    intermediate_results_callback,\n)\nSegmented Image with:\n  labels map: 400×400 Matrix{Int64}\n  number of labels: 12\n\njulia> intermediate_data\nDict{Any, Any} with 16 entries:\n  :binarized_tiling                       => Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0]\n  :icemask                                => Bool[1 1 … 1 1; 1 1 … 1 1; … ; 0 0 … 1 1; 0 0 … 1 1]\n  :equalized_gray                         => [0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0]\n  :morphed_residue                        => [0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0]\n  :L0mask                                 => Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0]\n  :segmented                              => Segmented Image with:…\n  :prelim_icemask2                        => [255 255 … 255 255; 255 255 … 255 255; … ; 255 255 … 255 255; 255 255 … 255 255]\n  :equalized_gray_sharpened_reconstructed => [0 0 … 0 0; 0 0 … 0 0; … ; 255 255 … 255 255; 255 255 … 255 255]\n  :gammagreen                             => [190.35 190.23 … 182.93 185.03; 191.68 190.6 … 185.04 192.08; … ; 163.87 173.33 … 108.02 108.18; 166.14 173.3 … 112.35 112.32]\n  :segment_mask                           => Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0]\n  :ref_img_cloudmasked                    => RGB{N0f8}[RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.008,0.706,0.761) RGB{N0f8}(0.0,0.722,0.769); RGB{N0f8}(0.0,0.0,0.0) RGB{N0f8}(0.0,0.0,0.0) … RGB{N0f8}(0.039,0.702,0.784) RGB{N0f8}(0.075,0.784,0.859); … ; RGB{…\n  :prelim_icemask                         => Bool[0 0 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0]\n  :equalized_gray_reconstructed           => [0 0 … 0 0; 0 0 … 0 0; … ; 255 255 … 255 255; 255 255 … 255 255]\n  :final                                  => Bool[0 0 … 0 0; 0 1 … 1 0; … ; 0 0 … 1 0; 0 0 … 0 0]\n  :local_maxima_mask                      => [255 255 … 255 255; 255 255 … 255 255; … ; 255 255 … 255 255; 255 255 … 255 255]\n  :labeled                                => [0 0 … 0 0; 0 1 … 1 0; … ; 0 0 … 9 0; 0 0 … 0 0]\n\n\n\n\n\n","category":"method"},{"location":"#IceFloeTracker.Utils.@persist","page":"IceFloeTracker.jl","title":"IceFloeTracker.Utils.@persist","text":"@persist img fname\n@persist(img,fname)\n@persist img\n@persist(img)\n@persist img fname ts\n@persist(img, fname, ts)\n\nGiven a reference to an image object img, the macro persists (saves to a file) img to the current working directory using fname as filename. Returns img.\n\nArguments\n\nimg: Symbol expression representing an image object loaded in memory.\nfname: Optional filename for the persisted image.\nts: Optional boolean to attach timestamp to fname.\n\n\n\n\n\n","category":"macro"},{"location":"#Unsorted-Functions","page":"IceFloeTracker.jl","title":"Unsorted Functions","text":"","category":"section"},{"location":"","page":"IceFloeTracker.jl","title":"IceFloeTracker.jl","text":"todo: Functions here still need to be sorted\nThe functions which are shown in this section  will be reorganized into submodules.","category":"page"},{"location":"#Index","page":"IceFloeTracker.jl","title":"Index","text":"","category":"section"},{"location":"","page":"IceFloeTracker.jl","title":"IceFloeTracker.jl","text":"","category":"page"}]
}
